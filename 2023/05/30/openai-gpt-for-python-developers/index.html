

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Felix Yang">
  <meta name="keywords" content="Python,SRE,Flask,AWS,Azure,运维， 读书">
  
    <meta name="description" content="[TOC] 前言What is ChatGPT, GPT, GPT-3, DALL-E, Codex?Story of OpenAIAn artificial intelligence research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-pr">
<meta property="og:type" content="article">
<meta property="og:title" content="OpenAI GPT For Python Developers">
<meta property="og:url" content="https://blog.excelsre.com/2023/05/30/openai-gpt-for-python-developers/index.html">
<meta property="og:site_name" content="Felix Yang&#39;s Blog">
<meta property="og:description" content="[TOC] 前言What is ChatGPT, GPT, GPT-3, DALL-E, Codex?Story of OpenAIAn artificial intelligence research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-pr">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://felixyanghui.synology.me:8441/images/2023/05/30/image-20230530182644993.png">
<meta property="og:image" content="https://felixyanghui.synology.me:8441/images/2023/06/10/ai-vs-machine-learning-vs-deep-learning.png">
<meta property="article:published_time" content="2023-05-30T10:22:46.000Z">
<meta property="article:modified_time" content="2023-06-29T07:21:42.850Z">
<meta property="article:author" content="Felix Yang">
<meta property="article:tag" content="读书笔记">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="GPT">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://felixyanghui.synology.me:8441/images/2023/05/30/image-20230530182644993.png">
  
  
  
  <title>OpenAI GPT For Python Developers - Felix Yang&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.excelsre.com","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":120,"cursorChar":"_","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Felix Yang's Blog" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="Felix Yang's Blog" type="application/rss+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>大良造</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">OpenAI GPT For Python Developers</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-05-30 18:22" pubdate>
          2023年5月30日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          79k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          656 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">OpenAI GPT For Python Developers</h1>
            
            
              <div class="markdown-body">
                
                <hr>
<p><img src="https://felixyanghui.synology.me:8441/images/2023/05/30/image-20230530182644993.png" srcset="/img/loading.gif" lazyload alt="image-20230530182644993"></p>
<p>[TOC]</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h2 id="What-is-ChatGPT-GPT-GPT-3-DALL-E-Codex"><a href="#What-is-ChatGPT-GPT-GPT-3-DALL-E-Codex" class="headerlink" title="What is ChatGPT, GPT, GPT-3, DALL-E, Codex?"></a>What is ChatGPT, GPT, GPT-3, DALL-E, Codex?</h2><h3 id="Story-of-OpenAI"><a href="#Story-of-OpenAI" class="headerlink" title="Story of OpenAI"></a>Story of OpenAI</h3><p>An artificial intelligence research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc.</p>
<ul>
<li><p>成立于Y2015, 成立之初的愿景：promoting and developing a friendly AI in a way that benefits humanity as a whole。 </p>
</li>
<li><p><em><strong>Sam Altman, Elon Musk,</strong> Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon</em></p>
<p><em>Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged</em></p>
<p><em>over <strong>US$1 billion</strong> to the venture.</em></p>
</li>
<li><p>Y2016, relase “Universe”, a software platform for measuring and training an AI’s general intelligence accross the world’s supply of games, websites and other applications</p>
</li>
<li><p><strong>Y2018, Elon Musk resigned from his board seat</strong>, but remained a donor.</p>
</li>
<li><p>Y2019, transitioned from non-profit to capped-profit (profit cap set to 100 times on any investment), The company distributed equity to its employees and partnered with <strong>Microsoft, which announced an investment package of US$1 billion into the company</strong>.</p>
</li>
<li><p>Y2020, GPT-3, a language model trained on trillions of words from the Internet.</p>
</li>
<li><p>Y2021, DALL-E, a deep-learning model that can generate digital images from natural language descriptions.</p>
</li>
<li><p><strong>Y2022, ChatGPT  - 自此开始全球风靡</strong></p>
</li>
</ul>
<h3 id="ChatGPT"><a href="#ChatGPT" class="headerlink" title="ChatGPT"></a>ChatGPT</h3><p>ChatGPT simply stands for <strong>G</strong>enerative <strong>P</strong>re-trained <strong>T</strong>ransformer, is built on top of OpenAI’s GPT-3 family of large language models.</p>
<p>Other projects using GPT-3 are:</p>
<ul>
<li><p><em>GitHub Copilot (using the OpenAI Codex model, a descendant of GPT-3, fine-tuned for generating code)</em></p>
</li>
<li><p><em>Copy.ai and  Jasper.ai (content generation for marketing purposes)</em></p>
</li>
<li><p><em>Drexel University (detection of early signs of Alzheimer’s disease)</em></p>
</li>
<li><p><em>Algolia (enhancing their search engine capabilities)</em></p>
</li>
</ul>
<h3 id="What-we-can-do-with-GPT"><a href="#What-we-can-do-with-GPT" class="headerlink" title="What we can do with GPT?"></a>What we can do with GPT?</h3><ol>
<li><p><em>By the end of your learning journey, you will have built applications such as:</em></p>
<ul>
<li><p>A fine-tuned medical chatbot assistant</p>
</li>
<li><p>An intelligent coffee recommendation system</p>
</li>
<li><p>An intelligent conversational system with memory and context</p>
</li>
<li><p>An AI voice assistant like Alexa but smarter</p>
</li>
<li><p>A Chatbot assistant to help with Linux commands</p>
</li>
<li><p>A semantic search engine</p>
</li>
<li><p>A news category prediction system</p>
</li>
<li><p>An image recognition intelligent system (image to text)</p>
</li>
<li><p>An image generator (text to image)</p>
</li>
<li><p>and more!</p>
</li>
</ul>
</li>
<li><p>By reading this guide and following the examples, you will be able to:</p>
<ul>
<li><p>Understand the different models available, and how and when to use each one.</p>
</li>
<li><p>Generate human-like text for various purposes, such as answering questions, creating content, and other creative uses.</p>
</li>
<li><p>Control the creativity of GPT models and adopt the best practices to generate high-quality text.</p>
</li>
<li><p>Transform and edit the text to perform translation, formatting, and other useful tasks.</p>
</li>
<li><p>Optimize the performance of GPT models using the various parameters and options such as suffix, max_tokens, temperature, top_p, n, stream, logprobs, echo, stop, presence_penalty, frequency_penalty, best_of, and others.</p>
</li>
<li><p>Stem, lemmatize, and reduce your bills when using the API</p>
</li>
<li><p>Understand Context Stuffing, chaining, and practice using advanced techniques</p>
</li>
<li><p>Understand text embedding and how companies such as Tesla and Notion are using it</p>
</li>
<li><p>Understand and implement semantic search and other advanced tools and concepts.</p>
</li>
<li><p>Creating prediction algorithms and zero-shot techniques and evaluating their accuracy </p>
</li>
<li><p>Understand, practice, and improve few-shot learning.</p>
</li>
<li><p>Understand fine-tuning and leveraging its power to create your own models.</p>
</li>
<li><p>Understand and use the best practices to create your own models.</p>
</li>
<li><p>Practice training and classification techniques using GPT.</p>
</li>
<li><p>Create advanced fine-tuned models.</p>
</li>
<li><p>Use OpenAI Whisper and other tools to create intelligent voice assistants.</p>
</li>
<li><p>Implement image classification using OpenAI CLIP.</p>
</li>
<li><p>Generate and edit images using OpenAI DALL-E.</p>
</li>
<li><p>Draw inspiration from other images to create yours.</p>
</li>
<li><p>Reverse engineer images’ prompts from Stable Diffusion (image to text)</p>
</li>
</ul>
</li>
</ol>
<h2 id="How-Does-GPT-Work"><a href="#How-Does-GPT-Work" class="headerlink" title="How Does GPT Work?"></a>How Does GPT Work?</h2><h3 id="Deep-Learning-Machine-Learning-and-AI"><a href="#Deep-Learning-Machine-Learning-and-AI" class="headerlink" title="Deep Learning, Machine Learning and AI"></a><a target="_blank" rel="noopener" href="https://learn.microsoft.com/zh-cn/azure/machine-learning/concept-deep-learning-vs-machine-learning?view=azureml-api-2">Deep Learning, Machine Learning and AI</a></h3><p><img src="https://felixyanghui.synology.me:8441/images/2023/06/10/ai-vs-machine-learning-vs-deep-learning.png" srcset="/img/loading.gif" lazyload alt="关系图：AI、深度学习与机器学习"></p>
<blockquote>
<ul>
<li><strong>Deep learning</strong> is a subset of machine learning that’s based on <strong>artificial neural networks</strong>. The <em>learning process</em> is <em>deep</em> because the structure of artificial neural networks consists of multiple input, output, and hidden layers. Each layer contains units that transform the input data into information that the next layer can use for a certain predictive task. Thanks to this structure, a machine can learn through its own data processing.</li>
<li><strong>Generative AI</strong> is a subset of artificial intelligence that uses techniques (such as deep learning) to generate new content. For example, you can use generative AI to create images, text, or audio. These models leverage massive pre-trained knowledge to generate this content.</li>
</ul>
</blockquote>
<h3 id="Artificial-neural-networks"><a href="#Artificial-neural-networks" class="headerlink" title="Artificial neural networks"></a>Artificial neural networks</h3><p>Artificial neural networks are formed by layers of connected nodes. Deep learning models use neural networks that have a large number of layers.</p>
<p>The following are most popular artificial neural network typologies and models</p>
<ul>
<li><p>Feedforward neural network</p>
</li>
<li><p>Recurrent neural network (RNN)</p>
</li>
<li><p>Convolutional neural network (CNN)</p>
</li>
<li><p>Generative adversarial network (GAN)</p>
</li>
<li><p><strong>Transformers</strong></p>
</li>
</ul>
<h3 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h3><p>Transformers are a model architecture of <strong>Artificial neural networks</strong> that is suited for solving problems containing sequences such as text or time-series data. They consist of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)#Encoder">encoder and decoder layers</a>. The encoder takes an input and maps it to a numerical representation containing information such as context. The decoder uses information from the encoder to produce an output such as translated text. What makes transformers different from other architectures containing encoders and decoders are the attention sub-layers. Attention is the idea of focusing on specific parts of an input based on the importance of their context in relation to other inputs in a sequence. For example, when summarizing a news article, not all sentences are relevant to describe the main idea. By focusing on key words throughout the article, summarization can be done in a single sentence, the headline.</p>
<p>Transformers have been used to solve natural language processing problems such as translation, text generation, question answering, and text summarization.</p>
<p>Some well-known implementations of transformers are:</p>
<ul>
<li>Bidirectional Encoder Representations from Transformers (BERT)</li>
<li>Generative Pre-trained Transformer 2 (<strong>GPT</strong>-2)</li>
<li>Generative Pre-trained Transformer 3 (<strong>GPT</strong>-3)</li>
</ul>
<h3 id="GPT-Generative-Pre-trained-Transformer"><a href="#GPT-Generative-Pre-trained-Transformer" class="headerlink" title="GPT (Generative Pre-trained Transformer)"></a>GPT (<strong>G</strong>enerative <strong>P</strong>re-trained <strong>T</strong>ransformer)</h3><p>GPT is a type of neural network called a transformer, which is specifically designed for natural language processing tasks. The architecture of a transformer is based on a series of <em><strong>self-attention</strong></em> mechanisms that allow the model to process input text in parallel and weigh the importance of each word or token based on its context.</p>
<h3 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h3><p>Self-attention is a mechanism used in deep learning models for natural language processing (NLP) that allows a model to weigh the importance of different parts of a sentence or a number of sentences when making predictions. Part of the Transformer architecture, it enables a neural network to achieve a satisfactory degree of performance when it comes to NLP tasks.</p>
<h3 id="How-GPT-generate-text-differently-from-other"><a href="#How-GPT-generate-text-differently-from-other" class="headerlink" title="How GPT generate text differently from other"></a>How GPT generate text differently from other</h3><p>An example of using Hugging Face transformers for GPT-2 interface</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">1</span> <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><span class="hljs-number">2</span> generator = pipeline(<span class="hljs-string">&#x27;text-generation&#x27;</span>, model = <span class="hljs-string">&#x27;gpt2&#x27;</span>)<br><span class="hljs-number">3</span> generator(<span class="hljs-string">&quot;Hello, I&#x27;m a language model&quot;</span>, max_length = <span class="hljs-number">30</span>, num_return_sequences=<span class="hljs-number">3</span>)<br><span class="hljs-number">4</span> <span class="hljs-comment">## [&#123;&#x27;generated_text&#x27;: &quot;Hello, I&#x27;m a language modeler. So while writing this, when I\</span><br><span class="hljs-number">5</span> went out to meet my wife <span class="hljs-keyword">or</span> come home she told me that my<span class="hljs-string">&quot;&#125;,</span><br><span class="hljs-string">6 ## &#123;&#x27;generated_text&#x27;: &quot;</span>Hello, I<span class="hljs-string">&#x27;m a language modeler. I write and maintain software\</span><br><span class="hljs-string">7 in Python. I love to code, and that includes coding things that require writing&quot;&#125;, \</span><br><span class="hljs-string">8 ...</span><br></code></pre></td></tr></table></figure>

<p>By default, a model has no memory, this means that each input is processed independently, without any information being carried over from previous inputs. When GPT generates text, it doesn’t have any preconceived notions about what should come next based on previous inputs. <strong>Instead, it generates <em>each word</em> based on the probability of it being the next likely word given the previous input</strong>. This results in text that can be surprising and creative.</p>
<p>默认情况下，模型没有内存，这意味着每个输入都是独立处理的，不需要从以前的输入传递任何信息。当GPT生成文本时，它不会根据之前的输入对下一步应该做什么有任何先入为主的概念。相反，它根据给定前一个输入的下一个可能<strong>单词</strong>的概率生成<strong>每个单词</strong>。这就产生了令人惊讶且富有创造性的文本。</p>
<p>This is another example of code that uses a GPT model to generate text based on user input.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Import the necessary libraries</span><br><span class="hljs-number">2</span> <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2Tokenizer, GPT2LMHeadModel<br><span class="hljs-number">3</span><br><span class="hljs-number">4</span> <span class="hljs-comment"># Load the pre-trained GPT-2 tokenizer and model</span><br><span class="hljs-number">5</span> tokenizer = GPT2Tokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)<br><span class="hljs-number">6</span> model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)<br><span class="hljs-number">7</span><br><span class="hljs-number">8</span> <span class="hljs-comment"># Set the model to evaluation mode</span><br><span class="hljs-number">9</span> model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-number">10</span><br><span class="hljs-number">11</span> <span class="hljs-comment"># Define a prompt for the model to complete</span><br><span class="hljs-number">12</span> prompt = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;You: &quot;</span>)<br><span class="hljs-number">13</span><br><span class="hljs-number">14</span> <span class="hljs-comment"># Tokenize the prompt and generate text</span><br><span class="hljs-number">15</span> input_ids = tokenizer.encode(prompt, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)<br><span class="hljs-number">16</span> output = model.generate(input_ids, max_length=<span class="hljs-number">50</span>, do_sample=<span class="hljs-literal">True</span>)<br><span class="hljs-number">17</span><br><span class="hljs-number">18</span> <span class="hljs-comment"># Decode the generated text and print it to the console</span><br><span class="hljs-number">19</span> generated_text = tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-number">20</span> <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;AI: &quot;</span> + generated_text)<br></code></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install openai<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install --upgrade openai<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br>openai.api_key = <span class="hljs-string">&#x27;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&#x27;</span><br><br>models = openai.Model.<span class="hljs-built_in">list</span>()<br>datas = models[<span class="hljs-string">&#x27;data&#x27;</span>]<br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> datas:<br>    <span class="hljs-built_in">print</span>(data[<span class="hljs-string">&#x27;id&#x27;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br>openai.api_key = <span class="hljs-string">&#x27;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&#x27;</span><br><br><br>response = openai.ChatCompletion.create(<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>    messages=[<br>        &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Assistant is a large language model trained by OpenAI.&quot;</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Who were the founders of Microsoft?&quot;</span>&#125;<br>    ]<br>)<br><br><span class="hljs-built_in">print</span>(response[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install transformers<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2Tokenizer, GPT2LMHeadModel<br><br>tokenizer = GPT2Tokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)<br>model = GPT2LMHeadModel.from_pretrained_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)<br><br>model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">openai.api_key = <span class="hljs-string">&#x27;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&#x27;</span><br><span class="hljs-built_in">print</span>(openai.api_key)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>models = openai.Model.<span class="hljs-built_in">list</span>()<br>datas = models[<span class="hljs-string">&#x27;data&#x27;</span>]<br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> datas:<br>    <span class="hljs-built_in">print</span>(data[<span class="hljs-string">&#x27;id&#x27;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">15</span>,<br>    temperature=<span class="hljs-number">0.5</span><br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h2 id="Using-GPT-Text-Completions"><a href="#Using-GPT-Text-Completions" class="headerlink" title="Using GPT Text Completions"></a>Using GPT Text Completions</h2><h3 id="Logprobs"><a href="#Logprobs" class="headerlink" title="Logprobs"></a>Logprobs</h3><p>To increase the possibilities, we can use the “logprobs” prameters. For example, setting logprobs to 2 will return two versions of each token</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">15</span>,<br>    temperature=<span class="hljs-number">0</span>,<br>    logprobs=<span class="hljs-number">3</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h3 id="Streaming-the-Results"><a href="#Streaming-the-Results" class="headerlink" title="Streaming the Results"></a>Streaming the Results</h3><p>Another common parameter we can use in OpenAI is the stream. It is possible to instruct the API to return a stream of tokens instead of a block containing all tokens. In this case, the API will return a generator that yields tokens in the order they were generated.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">7</span>,<br>    stream=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(<span class="hljs-built_in">next</span>))<br><br><br><span class="hljs-comment"># # * will unpack the generator</span><br><span class="hljs-comment"># print(*next, sep=&#x27;\n&#x27;)</span><br><br><span class="hljs-comment"># Read the generator text elements one by one</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">next</span>:<br>    <span class="hljs-built_in">print</span>(i[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>])<br></code></pre></td></tr></table></figure>

<h3 id="Controlling-Repetitivity-Frequency-and-Presence-Penalties"><a href="#Controlling-Repetitivity-Frequency-and-Presence-Penalties" class="headerlink" title="Controlling Repetitivity: Frequency and Presence Penalties"></a>Controlling Repetitivity: Frequency and Presence Penalties</h3><p>the completions API has two features that can be used to stop the same words from being suggested too often. These features change the chances of certain words being suggested by adding a bonus or penalty to the logits(the numbers that show how likely a word is to be suggested)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">100</span>,<br>    frequency_penalty=<span class="hljs-number">2.0</span>,<br>    presence_penalty=<span class="hljs-number">2.0</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;=== Frequency and presence penalty 2.0 ===&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>])<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">100</span>,<br>    frequency_penalty=-<span class="hljs-number">2.0</span>,<br>    presence_penalty=-<span class="hljs-number">2.0</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;=== Frequency and presence penalty -2.0 ===&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">5</span>,<br>    n=<span class="hljs-number">2</span><br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h3 id="Getting-the-“best-of”"><a href="#Getting-the-“best-of”" class="headerlink" title="Getting the “best of”"></a>Getting the “best of”</h3><p>It is possible to ask the AI models to generate possible completions for a given task on the server side and select the one with the highest probability of being correct. This can be done using the <code>best_of</code> parameter.<br>When using <code>best_of</code>, you need to specify two numbers: <strong>n</strong> and <strong>best_of</strong><br>As seen previously, n is the number of candidate completions you want to see.<br>Note: Make sure that best_of is greater than n.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">5</span>,<br>    n=<span class="hljs-number">1</span>,<br>    best_of=<span class="hljs-number">2</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h3 id="Controlling-when-the-completion-stops"><a href="#Controlling-when-the-completion-stops" class="headerlink" title="Controlling when the completion stops"></a>Controlling when the completion stops</h3><p>In most cases, it is useful to stop the API from generating more text.</p>
<p>Let’s say, we want to generate a single paragraph and no more. In this case, we can ask the API to stop completing the text when there’s a new line(\n). This can be done using a similar code as below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">5</span>,<br>    stop=[<span class="hljs-string">&quot;\n&quot;</span>,],<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<p>The stop parameter can contain up to four stop words. Note that the completion will not include the stop sequence in the result. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Once upon a time&quot;</span>,<br>    max_tokens=<span class="hljs-number">5</span>,<br>    stop=[<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-string">&quot;Story&quot;</span>, <span class="hljs-string">&quot;End&quot;</span>, <span class="hljs-string">&quot;Once upon a time&quot;</span>],<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h3 id="Using-Suffic-after-text-completion"><a href="#Using-Suffic-after-text-completion" class="headerlink" title="Using Suffic after text completion"></a>Using Suffic after text completion</h3><p>The parameter suffix comes after the completion of inserted text.</p>
<p>Imagine, we want to crate a Python dict containing the list of primary numbers between 0 and 9:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yml">&#123;<br>    <span class="hljs-attr">&quot;primes&quot;:</span> [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>]<br>&#125;<br></code></pre></td></tr></table></figure>

<p>The API, in this case, is upposed to return 2, 3, 5, 7. We can use the suffic parmeter in this case.</p>
<p>Example-1:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Write a JSON containing primary numbers between 0 and 9 \n\n&#123;\n\t\&quot;primes\&quot;: [&quot;</span>,<br>)<br><br><span class="hljs-comment"># print(next[&quot;choices&quot;][0][&quot;text&quot;])</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<p>Example-2:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Write a JSON containing primary numbers between 0 and 9 \n\n&#123;\n\t\&quot;primes\&quot;: [&quot;</span>,<br>    suffix=<span class="hljs-string">&quot;]\n&#125;&quot;</span><br>)<br><br><span class="hljs-comment"># print(next[&quot;choices&quot;][0][&quot;text&quot;])</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h3 id="Extracting-keywords"><a href="#Extracting-keywords" class="headerlink" title="Extracting keywords"></a>Extracting keywords</h3><p>Through appending the keywords at the end of the prompt message to get the completion text, the model will recognize that we need keywords and output should look something like this:<br><code>Plankalku\u0308l, Fortran, ALGOL 58, Lisp</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;The first programming language to be invented was Plankalkül, which was designed by \</span><br><span class="hljs-string">Konrad Zuse in the 1940s, but not publicly known until 1972 (and not implemented unt\</span><br><span class="hljs-string">il 1998). The first widely known and successful high-level programming language was \</span><br><span class="hljs-string">Fortran, developed from 1954 to 1957 by a team of IBM researchers led by John Backus\</span><br><span class="hljs-string">. The success of FORTRAN led to the formation of a committee of scientists to develo\</span><br><span class="hljs-string">p a &quot;universal&quot; computer language; the result of their effort was ALGOL 58. Separate\</span><br><span class="hljs-string">ly, John McCarthy of MIT developed Lisp, the first language with origins in academia\</span><br><span class="hljs-string">to be successful. With the success of these initial efforts, programming languages \</span><br><span class="hljs-string">became an active topic of research in the 1960s and beyond.\n\nKeywords:&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">300</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>])<br></code></pre></td></tr></table></figure>

<p>You can play with the prompt and try different things such as: <code>Keywords:\n-</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;The first programming language to be invented was Plankalkül, which was designed by \</span><br><span class="hljs-string">Konrad Zuse in the 1940s, but not publicly known until 1972 (and not implemented unt\</span><br><span class="hljs-string">il 1998). The first widely known and successful high-level programming language was \</span><br><span class="hljs-string">Fortran, developed from 1954 to 1957 by a team of IBM researchers led by John Backus\</span><br><span class="hljs-string">. The success of FORTRAN led to the formation of a committee of scientists to develo\</span><br><span class="hljs-string">p a &quot;universal&quot; computer language; the result of their effort was ALGOL 58. Separate\</span><br><span class="hljs-string">ly, John McCarthy of MIT developed Lisp, the first language with origins in academia\</span><br><span class="hljs-string">to be successful. With the success of these initial efforts, programming languages \</span><br><span class="hljs-string">became an active topic of research in the 1960s and beyond.\n\nKeywords:\n-&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">300</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet.choices[<span class="hljs-number">0</span>].text)<br></code></pre></td></tr></table></figure>

<h3 id="Generating-Tweets"><a href="#Generating-Tweets" class="headerlink" title="Generating Tweets"></a>Generating Tweets</h3><p>We can apped “tweet:” instead of “Keywords:” to prompt the model to return the tweet-style message.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;The first programming language to be invented was Plankalkül, which was designed by \</span><br><span class="hljs-string">Konrad Zuse in the 1940s, but not publicly known until 1972 (and not implemented unt\</span><br><span class="hljs-string">il 1998). The first widely known and successful high-level programming language was \</span><br><span class="hljs-string">Fortran, developed from 1954 to 1957 by a team of IBM researchers led by John Backus\</span><br><span class="hljs-string">. The success of FORTRAN led to the formation of a committee of scientists to develo\</span><br><span class="hljs-string">p a &quot;universal&quot; computer language; the result of their effort was ALGOL 58. Separate\</span><br><span class="hljs-string">ly, John McCarthy of MIT developed Lisp, the first language with origins in academia\</span><br><span class="hljs-string">to be successful. With the success of these initial efforts, programming languages \</span><br><span class="hljs-string">became an active topic of research in the 1960s and beyond.\n\nTweet:&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">300</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet.choices[<span class="hljs-number">0</span>].text)<br></code></pre></td></tr></table></figure>

<p>We can also add hashtags with <code>Tweet with hashtags:</code>, here’s the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;The first programming language to be invented was Plankalkül, which was designed by \</span><br><span class="hljs-string">Konrad Zuse in the 1940s, but not publicly known until 1972 (and not implemented unt\</span><br><span class="hljs-string">il 1998). The first widely known and successful high-level programming language was \</span><br><span class="hljs-string">Fortran, developed from 1954 to 1957 by a team of IBM researchers led by John Backus\</span><br><span class="hljs-string">. The success of FORTRAN led to the formation of a committee of scientists to develo\</span><br><span class="hljs-string">p a &quot;universal&quot; computer language; the result of their effort was ALGOL 58. Separate\</span><br><span class="hljs-string">ly, John McCarthy of MIT developed Lisp, the first language with origins in academia\</span><br><span class="hljs-string">to be successful. With the success of these initial efforts, programming languages \</span><br><span class="hljs-string">became an active topic of research in the 1960s and beyond.\n\nTweet with hashtags:&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">300</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet.choices[<span class="hljs-number">0</span>].text)<br></code></pre></td></tr></table></figure>

<h3 id="Generating-a-Rap-Song"><a href="#Generating-a-Rap-Song" class="headerlink" title="Generating a Rap Song"></a>Generating a Rap Song</h3><ul>
<li>Example-1 with <code>text-davinci-002</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;Write a rap song:\n\n&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">200</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>

<ul>
<li>Example-1 with <code>text-davinci-003</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;Write a rap song:\n\n&#x27;</span><br><br>tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">200</span>,<br>)<br><br><span class="hljs-built_in">print</span>(tweet.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>

<h3 id="Generating-a-Todo-List"><a href="#Generating-a-Todo-List" class="headerlink" title="Generating a Todo List"></a>Generating a Todo List</h3><p>In this example, we are asking the model to generate a to-do list for creating a company in the US. We need five items on the list</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-built_in">next</span> = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>    prompt=<span class="hljs-string">&quot;Todo list to create a company in US\n\n1.&quot;</span>,<br>    temperature=<span class="hljs-number">0.3</span>,<br>    max_tokens=<span class="hljs-number">64</span>,<br>    top_p=<span class="hljs-number">0.1</span>,<br>    frequency_penalty=<span class="hljs-number">0</span>,<br>    presence_penalty=<span class="hljs-number">0.5</span>,<br>    stop=[<span class="hljs-string">&quot;6.&quot;</span>],<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>)<br></code></pre></td></tr></table></figure>

<h4 id="model"><a href="#model" class="headerlink" title="model:"></a>model:</h4><p>specifies the model that the API should use for generating the text completion. In this case,<br>it is using “text-davinci-002”.</p>
<h4 id="prompt"><a href="#prompt" class="headerlink" title="prompt:"></a>prompt:</h4><p>is the text that the API uses as a starting point for generating the completion. In our case,<br>we used a prompt that is a to-do list for creating a company in the US. The first item should start<br>with “1.”, knowing that the output we asked for should be in this format;<br>1 1. &lt;1st item&gt;<br>2 2. &lt;2nd item&gt;<br>3 3. &lt;3nd item&gt;<br>4 4. &lt;4th item&gt;<br>5 5. &lt;5th item&gt;</p>
<h4 id="temperature"><a href="#temperature" class="headerlink" title="temperature"></a>temperature</h4><p>controls the “creativity” of the text generated by the model. The higher temperature the<br>more creative and diverse completions will be. On the other hand, a lower temperature will result<br>in a more “conservative” and predictable completions. In this case, the temperature is set to 0.3.</p>
<h4 id="max-tokens"><a href="#max-tokens" class="headerlink" title="max_tokens"></a>max_tokens</h4><p>limits the maximum number of tokens that the API will generate. In our case, the<br>maximum number of tokens is 64. You can increase this value but keep in mind that the more<br>tokens you will generate, the more credits you will be charged. When learning and testing, keeping<br>a lower value will help you avoid overspending.</p>
<h4 id="top-p"><a href="#top-p" class="headerlink" title="top_p"></a>top_p</h4><p>controls the proportion of the mass of the distribution that the API considers when generating<br>the next token. A higher value will result in more conservative completions, while a lower value will<br>result in more diverse completions. In this case, the top_p is set to 0.1. It is not recommended to use<br>both this and temperature but it’s not also a blocking issue.</p>
<h4 id="frequency-penalty"><a href="#frequency-penalty" class="headerlink" title="frequency_penalty"></a>frequency_penalty</h4><p>is used to adjust the model’s preference for generating frequent or rare words.<br>A positive value will decrease the chances of frequent words, while a negative value will increase<br>them. In this case, the frequency_penalty is set to 0<br>presence_penalty is used to adjust the model’s preference for generating words that are present or<br>absent in the prompt. A positive value will decrease the chances of words that are present in the<br>prompt, a negative value will increase them. The presence_penalty is set to 0.5 in our example.</p>
<h4 id="stop"><a href="#stop" class="headerlink" title="stop"></a>stop</h4><p>is used to specify a sequence of tokens that the API should stop generating completions after. In<br>our example, since we only want 5 items, we should stop generating after the token 6. is generated.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>The OpenAI Completions API is a powerful tool for generating text in various contexts. With the<br>right parameters and settings, it can produce natural-sounding text that is pertinent to the task.<br>By configuring the right values for some parameters such as frequency and presence penalties, the<br>results can be tailored to produce desired outcomes.<br>With the ability to control when the completion stops, the user can also control the length of the<br>generated text. This could be also helpful to reduce the number of tokens generated and indirectly<br>reduce costs.</p>
<h2 id="Editing-Text-Using-GPT"><a href="#Editing-Text-Using-GPT" class="headerlink" title="Editing Text Using GPT"></a>Editing Text Using GPT</h2><p>After being given a prompt and a set of instructions, the GPT model you are using will take the prompt and then use its algorithms to generate a modified version of the original prompt.</p>
<p>The modified version can be longer and&#x2F;or more detailed than the initial prompt depending on your instructions.</p>
<p>A GPT model is able to understand the context of the prompt of the prompt and the instructions given, allowing it to determine which additional details would be most beneficial to include in the output. </p>
<h3 id="Tanslating-Text"><a href="#Tanslating-Text" class="headerlink" title="Tanslating Text"></a>Tanslating Text</h3><p>This is an example:</p>
<ul>
<li>Use API endipoint: openai.Edit.create</li>
<li>Use instruction and input (optional)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&#x27;Hallo Welt&#x27;</span>,<br>    instruction=<span class="hljs-string">&#x27;Translate to English&#x27;</span>,<br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(response)<br></code></pre></td></tr></table></figure>

<p>The other example with instruction only, without input:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;Translate the following sentence to English: &#x27;Hallo Welt&#x27;&quot;</span>,<br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(response)<br></code></pre></td></tr></table></figure>

<h3 id="Editing-using-the-completions-endpoint-and-vice-versa"><a href="#Editing-using-the-completions-endpoint-and-vice-versa" class="headerlink" title="Editing using the completions endpoint and vice versa"></a>Editing using the completions endpoint and vice versa</h3><p>Some tasks you can excute using the edits endpoint can be done using the completions endpoint. It is up to you to choose which one is best for your needs.<br>Here’s an example of a translation task using the edits endpoint:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Example using edit dendpoint</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;Translate from English to Japanese, French, Arabic, and Spanish. /n 1:Japanese: &quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;The cat sat on the mat&quot;</span><br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(response)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Example using completion endpoint</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>content=<span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Translate the following sentence from English to Japanese, French, Arabic, and Spanish.</span><br><span class="hljs-string">    The cat sat on the mat.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>response = openai.ChatCompletion.create(<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>    messages=[<br>        &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: content&#125;,<br>    ],<br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].message.content)<br><span class="hljs-comment"># print(response)</span><br></code></pre></td></tr></table></figure>

<h3 id="Formatting-the-output"><a href="#Formatting-the-output" class="headerlink" title="Formatting the output"></a>Formatting the output</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Example to add comments to a Golang code</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>message=<span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">package main</span><br><span class="hljs-string"></span><br><span class="hljs-string">import (</span><br><span class="hljs-string">&quot;io/ioutil&quot;</span><br><span class="hljs-string">&quot;log&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br><span class="hljs-string">)</span><br><span class="hljs-string"></span><br><span class="hljs-string">func main() &#123;</span><br><span class="hljs-string">resp, err := http.Get(&quot;https://website.com&quot;)</span><br><span class="hljs-string"></span><br><span class="hljs-string">if err != nil &#123;</span><br><span class="hljs-string">log.Fatalln(err)</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">body, err := ioutil.ReadAll(resp.Body)</span><br><span class="hljs-string">if err != nil &#123;</span><br><span class="hljs-string">log.Fatalln(err)</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">sb := string(body)</span><br><span class="hljs-string">log.Printf(sb)</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br>response = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;Explain the following Golang code&quot;</span>,<br>    <span class="hljs-built_in">input</span>=message,<br>    temperature=<span class="hljs-number">0.5</span><br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].text)<br></code></pre></td></tr></table></figure>

<h3 id="Creativity-vs-Well-defined-answers"><a href="#Creativity-vs-Well-defined-answers" class="headerlink" title="Creativity vs. Well-defined answers"></a>Creativity vs. Well-defined answers</h3><p>Same as the completions endpoint, we have control over the creativity of the result using the temperature parameter.<br>You can try this example using two different temperatures to see the difference in the output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response_1 = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;correct the spelling mistakes:&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;The kuick brown fox jumps over the lazy dog and&quot;</span>,<br>    temperature=<span class="hljs-number">0</span>,<br>)<br><br>response_2 = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;correct the spelling mistakes:&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;The kuick brown fox jumps over the lazy dog and&quot;</span>,<br>    temperature=<span class="hljs-number">0.9</span>,<br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Temperature 0:&quot;</span>)<br><span class="hljs-built_in">print</span>(response_1.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Temperature 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(response_2.choices[<span class="hljs-number">0</span>].text)<br></code></pre></td></tr></table></figure>

<blockquote>
<p>Generally, after running the code multiple times, you may observe that the first output is consistent, while the second one changes from one execution to the next. For a use case such as fixing typos, we usually don;t need creativity, so setting the temperature parameter to 0 is enough.<br>We can also use <code>top_p</code> to add the creativitiy, it is similar to the temperature. It means only tokens comprising the top #% probability mass are considered in the result.</p>
</blockquote>
<h3 id="Generating-multiple-edits"><a href="#Generating-multiple-edits" class="headerlink" title="Generating multiple edits"></a>Generating multiple edits</h3><p>In all of the previous examples, we always had a single edit. However, using the parameter n, it is possible to get more. Just use the number of edits you want to have:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    instruction=<span class="hljs-string">&quot;Edit the text to make it longer.&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;Exercise is good for your health.&quot;</span>,<br>    top_p=<span class="hljs-number">0.2</span>,<br>    n=<span class="hljs-number">2</span><br>)<br><br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].text)<br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">1</span>].text)<br></code></pre></td></tr></table></figure>

<h2 id="Advanced-Text-Manipulation"><a href="#Advanced-Text-Manipulation" class="headerlink" title="Advanced Text Manipulation"></a>Advanced Text Manipulation</h2><p>Untill now, we have see how to use different endpoints: edits and completions. Let’s do more examples to understand the different possibilities the model offers.</p>
<h3 id="Chaining-completions-and-edits"><a href="#Chaining-completions-and-edits" class="headerlink" title="Chaining completions and edits"></a>Chaining completions and edits</h3><ul>
<li>Use completion endpoint to generate the tweet with hashtags.</li>
<li>Use generated tweet as the <code>input</code>, and use <code>instruction</code> to translate the tweet</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>prompt = <span class="hljs-string">&#x27;The first programming language to be invented was Plankalkül, which was designed by \</span><br><span class="hljs-string">Konrad Zuse in the 1940s, but not publicly known until 1972 (and not implemented unt\</span><br><span class="hljs-string">il 1998). The first widely known and successful high-level programming language was \</span><br><span class="hljs-string">Fortran, developed from 1954 to 1957 by a team of IBM researchers led by John Backus\</span><br><span class="hljs-string">. The success of FORTRAN led to the formation of a committee of scientists to develo\</span><br><span class="hljs-string">p a &quot;universal&quot; computer language; the result of their effort was ALGOL 58. Separate\</span><br><span class="hljs-string">ly, John McCarthy of MIT developed Lisp, the first language with origins in academia\</span><br><span class="hljs-string">to be successful. With the success of these initial efforts, programming languages \</span><br><span class="hljs-string">became an active topic of research in the 1960s and beyond.\n\nTweet with hashtags:&#x27;</span><br><br>english_tweet = openai.Completion.create(<br>    model=<span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>    prompt=prompt,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    max_tokens=<span class="hljs-number">20</span>,<br>)<br><br>english_tweet_text = english_tweet.choices[<span class="hljs-number">0</span>].text.strip()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;English tweet:&quot;</span>)<br><span class="hljs-built_in">print</span>(english_tweet_text)<br><br>spanish_tweet = openai.Edit.create(<br>    model=<span class="hljs-string">&quot;text-davinci-edit-001&quot;</span>,<br>    <span class="hljs-built_in">input</span>=english_tweet_text,<br>    instruction=<span class="hljs-string">&quot;Translate to Spanish&quot;</span>,<br>    temperature=<span class="hljs-number">0.5</span>,<br>    <br>)<br><br>spanish_tweet_text = spanish_tweet.choices[<span class="hljs-number">0</span>].text.strip()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Spanish tweet:&quot;</span>)<br><span class="hljs-built_in">print</span>(spanish_tweet_text)<br></code></pre></td></tr></table></figure>

<h3 id="Aple-the-Company-vs-Apple-the-Fruit-Context-Stuffing"><a href="#Aple-the-Company-vs-Apple-the-Fruit-Context-Stuffing" class="headerlink" title="Aple the Company vs. Apple the Fruit (Context Stuffing)"></a>Aple the Company vs. Apple the Fruit (Context Stuffing)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;Determine the part of speech of the word &#x27;light&#x27;.\n\n&quot;</span><br><br>result = openai.Completion.create(<br>    model = <span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>    prompt = prompt,<br>    max_tokens = <span class="hljs-number">20</span>,<br>    temperature = <span class="hljs-number">1</span>,<br>)<br><br><span class="hljs-built_in">print</span>(result.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt_a = <span class="hljs-string">&quot;The light is red. Determine the part of speech of the word &#x27;light&#x27;.\n\n&quot;</span><br>prompt_b = <span class="hljs-string">&quot;This desk is very light. Determine the part of speech of the word &#x27;light&#x27;.\n\n&quot;</span><br>prompt_c = <span class="hljs-string">&quot;You light up my life. Determine the part of speech of the word &#x27;light&#x27;.\n\n&quot;</span><br><br><span class="hljs-keyword">for</span> prompt <span class="hljs-keyword">in</span> [prompt_a, prompt_b, prompt_c]:<br>    result = openai.Completion.create(<br>        model=<span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>        prompt=prompt,<br>        max_tokens=<span class="hljs-number">20</span>,<br>        temperature=<span class="hljs-number">0</span>,<br>    )<br>    <span class="hljs-built_in">print</span>(result.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt_1 = <span class="hljs-string">&quot;Huawei:\ncompany\n\nGoogle:\ncompany\n\nMicrosoft:\ncompany\n\nApple:\n&quot;</span><br>prompt_2 = <span class="hljs-string">&quot;Huawei:\ncompany\n\nGoogle:\ncompany\n\nMicrosoft:\ncompany\n\nApricot:\nFruit\n\nApple:\n&quot;</span><br><br><span class="hljs-keyword">for</span> prompt <span class="hljs-keyword">in</span> [prompt_1, prompt_2]:<br>    result = openai.Completion.create(<br>        model = <span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>        prompt = prompt,<br>        max_tokens = <span class="hljs-number">20</span>,<br>        temperature = <span class="hljs-number">0</span>,<br>        stop=[<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-string">&quot; &quot;</span>],<br>    )<br><br>    <span class="hljs-built_in">print</span>(result.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>

<h3 id="Getting-cryptocurrency-information-based-on-a-user-defined-schema-context-stuffing"><a href="#Getting-cryptocurrency-information-based-on-a-user-defined-schema-context-stuffing" class="headerlink" title="Getting cryptocurrency information based on a user-defined schema (context stuffing)"></a>Getting cryptocurrency information based on a user-defined schema (context stuffing)</h3><ul>
<li>define a schema or template</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;&quot;&quot;Input: Bitcoin</span><br><span class="hljs-string">Output:</span><br><span class="hljs-string">BTC was created in 2008, you can learn more about it here: https://bitcoin.org/en/ a\</span><br><span class="hljs-string">nd get the latest price here: https://www.coingecko.com/en/coins/bitcoin.</span><br><span class="hljs-string">It&#x27;s all-time high is $64,895.00 and it&#x27;s all-time low is $67.81.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: Ethereum</span><br><span class="hljs-string">Output:</span><br><span class="hljs-string">ETH was created in 2015, you can learn more about it here: https://ethereum.org/en/ \</span><br><span class="hljs-string">and get the latest price here: https://www.coingecko.com/en/coins/ethereum</span><br><span class="hljs-string">It&#x27;s all-time high is $4,379.00 and it&#x27;s all-time low is $0.43.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: Dogecoin</span><br><span class="hljs-string">Output:</span><br><span class="hljs-string">DOGE was created in 2013, you can learn more about it here: https://dogecoin.com/ an\</span><br><span class="hljs-string">d get the latest price here: https://www.coingecko.com/en/coins/dogecoin</span><br><span class="hljs-string">It&#x27;s all-time high is $0.73 and it&#x27;s all-time low is $0.000002.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: Cardano</span><br><span class="hljs-string">Output:\n&quot;&quot;&quot;</span><br><br>result = openai.Completion.create(<br>    model = <span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>    prompt = prompt,<br>    max_tokens = <span class="hljs-number">200</span>,<br>    temperature = <span class="hljs-number">0</span>,<br>)<br><br><span class="hljs-built_in">print</span>(result.choices[<span class="hljs-number">0</span>].text.strip())<br></code></pre></td></tr></table></figure>

<h3 id="Creating-a-Chatbot-assistant-to-help-with-Linux-commands"><a href="#Creating-a-Chatbot-assistant-to-help-with-Linux-commands" class="headerlink" title="Creating a Chatbot assistant to help with Linux commands"></a>Creating a Chatbot assistant to help with Linux commands</h3><p>Disclaimer: This part was inspired by an old demo of OpenAI from 2020.<br>Our goal is to develop a command-line tool that can assist us with Linux commands through<br>conversation.<br>Let’s start with this example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install click==<span class="hljs-number">8.1</span><span class="hljs-number">.3</span><br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">import</span> click<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><br><br>_prompt = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Input: List all the files in the current directory</span><br><span class="hljs-string">Output: ls -l</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: List all the files in the current directory, including hidden files</span><br><span class="hljs-string">Output: ls -la</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: Delete all the files in the current directory</span><br><span class="hljs-string">Output: rm *</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: Count the number of occurrences of the word &quot;sun&quot; in the file &quot;test.txt&quot;</span><br><span class="hljs-string">Output: grep -o &quot;sun&quot; test.txt | wc -l</span><br><span class="hljs-string"></span><br><span class="hljs-string">Input: &#123;&#125;</span><br><span class="hljs-string">Output:&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    request = <span class="hljs-built_in">input</span>(click.style(<span class="hljs-string">&quot;Input(type &#x27;exit&#x27; to quit): &quot;</span>, fg=<span class="hljs-string">&quot;green&quot;</span>))<br>    <span class="hljs-keyword">if</span> request == <span class="hljs-string">&quot;exit&quot;</span>:<br>        <span class="hljs-keyword">break</span><br>        <br>    prompt = _prompt.<span class="hljs-built_in">format</span>(request)<br>    <br>    <span class="hljs-keyword">try</span>:<br>        result = openai.Completion.create(<br>            model = <span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>            prompt = prompt,<br>            max_tokens = <span class="hljs-number">100</span>,<br>            temperature = <span class="hljs-number">0</span>,<br>            stop=[<span class="hljs-string">&quot;\n&quot;</span>],<br>        )<br>        command = result.choices[<span class="hljs-number">0</span>].text.strip()<br>        click.echo(click.style(<span class="hljs-string">&quot;Output: &quot;</span>, fg=<span class="hljs-string">&quot;yellow&quot;</span>) + command)<br>        <br>        click.echo(click.style(<span class="hljs-string">&quot;Execute? (y/n): &quot;</span>, fg=<span class="hljs-string">&quot;yellow&quot;</span>), nl=<span class="hljs-literal">False</span>)<br>        choice = <span class="hljs-built_in">input</span>()<br>        <span class="hljs-keyword">if</span> choice == <span class="hljs-string">&quot;y&quot;</span>:<br>            os.system(command)<br>        <span class="hljs-keyword">elif</span> choice == <span class="hljs-string">&quot;n&quot;</span>:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">else</span>:<br>            click.echo(click.style(<span class="hljs-string">&quot;Invalid choice. Please enter &#x27;y&#x27; or &#x27;n&#x27;.&quot;</span>, fg=<span class="hljs-string">&quot;red&quot;</span>))<br>    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>        click.echo(click.style(<span class="hljs-string">&quot;The command could not be executed. &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(e), fg=<span class="hljs-string">&quot;red&quot;</span>))<br>        <span class="hljs-keyword">pass</span><br>    click.echo()<br></code></pre></td></tr></table></figure>

<h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><ul>
<li>measure how similar two text strings are to each other</li>
<li>used for tasks like:<ul>
<li>finding the most relevant results to a search query</li>
<li>grouping text strings together based on how similar they are</li>
<li>recommending items with similar text strings</li>
<li>finding text strings that are very different from the other</li>
<li>analyzing how different text srings are from each other</li>
<li>labeling text strings based on what they are most like.</li>
</ul>
</li>
</ul>
<p>Here’re some practical approaches to use embeddings in the industry.</p>
<ul>
<li>Tesla</li>
<li>Kalendar AI</li>
<li>Notion</li>
<li>DALL-E 2</li>
</ul>
<p>To work with embedding, you should install datalib using the following command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install datalib<br></code></pre></td></tr></table></figure>

<p>At another level of this guide, we will need Matplotlib and other libraries:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install matplotlib plotly scipy scikit-learn<br></code></pre></td></tr></table></figure>

<p>This package will also install tools like pandas and NumPy.<br>These libraries are some of the most used in AI and data science in general.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install datalib<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install matplotlib plotly scipy scikit-learn<br></code></pre></td></tr></table></figure>

<h3 id="Understanding-Text-Embedding"><a href="#Understanding-Text-Embedding" class="headerlink" title="Understanding Text Embedding"></a>Understanding Text Embedding</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br>response = openai.Embedding.create(<br>    model=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;I am a programmer&quot;</span>,<br>)<br><br><span class="hljs-built_in">print</span>(response)<br><br><span class="hljs-comment"># These floating points represent the embedding of the input text “I am a programmer” generated by the OpenAI “text-embedding-ada-002” model.</span><br></code></pre></td></tr></table></figure>

<h3 id="Embeddings-for-Multiple-Inputs"><a href="#Embeddings-for-Multiple-Inputs" class="headerlink" title="Embeddings for Multiple Inputs"></a>Embeddings for Multiple Inputs</h3><p>We can use multiple inputs to get the embeddings, here’s the example</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">response = openai.Embedding.create(<br>    model=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>,<br>    <span class="hljs-built_in">input</span>=[<span class="hljs-string">&quot;I am a programmer&quot;</span>, <span class="hljs-string">&quot;I am a writer&quot;</span>],<br>)<br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> response.data:<br>    <span class="hljs-built_in">print</span>(data.embedding)<br></code></pre></td></tr></table></figure>

<h3 id="Semantic-Search-语义搜索"><a href="#Semantic-Search-语义搜索" class="headerlink" title="Semantic Search - 语义搜索"></a>Semantic Search - 语义搜索</h3><p>We are going to implement a semantic search using OpenAI embeddings</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> openai.embeddings_utils <span class="hljs-keyword">import</span> get_embedding, cosine_similarity<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br>init_api()<br><br><span class="hljs-comment"># words.csv is a csv file with a column named &#x27;text&#x27; containing words</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;words.csv&#x27;</span>)<br><br><span class="hljs-comment"># get the embeddings for each word in the dataframe</span><br>df[<span class="hljs-string">&#x27;embedding&#x27;</span>] = df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: get_embedding(x, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>))<br><br><span class="hljs-comment"># save the dataframe to a csv file</span><br>df.to_csv(<span class="hljs-string">&#x27;embedding.csv&#x27;</span>)<br><br><span class="hljs-comment"># read the csv file</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;embedding.csv&#x27;</span>)<br><br><span class="hljs-comment"># convert the embedding axis to a numpy array</span><br>df[<span class="hljs-string">&#x27;embedding&#x27;</span>] = df[<span class="hljs-string">&#x27;embedding&#x27;</span>].apply(<span class="hljs-built_in">eval</span>).apply(np.array)<br><br><span class="hljs-comment"># get the search term from the user</span><br>user_search = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;Enter a search term: &#x27;</span>)<br><br><span class="hljs-comment"># get the embedding for the search term</span><br>search_term_embedding = get_embedding(user_search, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>)<br><br><span class="hljs-comment"># calculate the cosine similarity between the search term and each word in the dataframe</span><br>df[<span class="hljs-string">&#x27;similarity&#x27;</span>] = df[<span class="hljs-string">&#x27;embedding&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: cosine_similarity(x, search_term_embedding))<br><br><span class="hljs-comment"># sort the dataframe by the similarity axis</span><br>df = df.sort_values(by=<span class="hljs-string">&#x27;similarity&#x27;</span>, ascending=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># print the top 10 results</span><br><span class="hljs-built_in">print</span>(df.head(<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>

<h3 id="Cosine-Similarity"><a href="#Cosine-Similarity" class="headerlink" title="Cosine Similarity"></a>Cosine Similarity</h3><p>Cosine similarity is a way of measuring how similar two vectors are. It looks at the angle between<br>two vectors (lines) and compares them. Cosine similarity is the cosine of the angle between the<br>vector. A result is a number between -1 and 1. If the vectors are the same, the result is 1. If the<br>vectors are completely different, the result is -1. If the vectors are at a 90-degree angle, the result is 0. In mathematical terms, this is the equation:<br>$$<br>Similarity &#x3D; (A.B) &#x2F; (||A||.||B||)<br>$$</p>
<ul>
<li>A and B are vectors</li>
<li>A.B is a way of multiplying two sets of numbers together. It is done by taking each number in one set and multiplying it with the same number in the other set, then adding all of those products together.</li>
<li>||A|| is the length of the vector A. It is calculated by taking the square root of the sum of the squares of each element of the vector A.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># import numpy and norm from numpy.linalg</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> numpy.linalg <span class="hljs-keyword">import</span> norm<br><br><span class="hljs-comment"># define two vectors</span><br>A = np.array([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>B = np.array([<span class="hljs-number">3</span>,<span class="hljs-number">6</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">9</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>])<br><br><span class="hljs-comment"># print the vectors</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Vector A: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(A))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Vector B: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(B))<br><br><span class="hljs-comment"># calculate the cosine similarity</span><br>cosine = np.dot(A,B)/(norm(A)*norm(B))<br><br><span class="hljs-comment"># print the cosine similarity</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Cosine Similarity between A and B: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(cosine))<br></code></pre></td></tr></table></figure>

<h2 id="Advanced-Embedding-Examples"><a href="#Advanced-Embedding-Examples" class="headerlink" title="Advanced Embedding Examples"></a>Advanced Embedding Examples</h2><h3 id="Predicting-your-preferred-Coffee"><a href="#Predicting-your-preferred-Coffee" class="headerlink" title="Predicting your preferred Coffee"></a>Predicting your preferred Coffee</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install nltk<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">from</span> openai.embeddings_utils <span class="hljs-keyword">import</span> get_embedding, cosine_similarity<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">download_nltk_data</span>():<br>    <span class="hljs-keyword">try</span>:<br>        nltk.data.find(<span class="hljs-string">&#x27;tokenizers/punkt&#x27;</span>)<br>    <span class="hljs-keyword">except</span> LookupError:<br>        nltk.download(<span class="hljs-string">&#x27;punkt&#x27;</span>)<br>    <span class="hljs-keyword">try</span>:<br>        nltk.data.find(<span class="hljs-string">&#x27;corpora/stopwords&#x27;</span>)<br>    <span class="hljs-keyword">except</span> LookupError:<br>        nltk.download(<span class="hljs-string">&#x27;stopwords&#x27;</span>)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_review</span>(<span class="hljs-params">review</span>):<br>    <span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords<br>    <span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> PorterStemmer<br>    stopwords = <span class="hljs-built_in">set</span>(stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>))<br>    stemmer = PorterStemmer()<br>    tokens = nltk.word_tokenize(review.lower())<br>    tokens = [token <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords]<br>    tokens = [stemmer.stem(token) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join(tokens)<br><br>init_api()<br><br>download_nltk_data()<br><br><span class="hljs-comment"># Read user input</span><br>input_coffee_name = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Enter a coffee name: &quot;</span>)<br><br><span class="hljs-comment"># Load the CSV file into a Pandas DataFrame </span><br><span class="hljs-comment"># (only the first 50 rows for now to speed up the demo and avoid paying for too many API calls)</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;simplified_coffee.csv&#x27;</span>, nrows=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Preprocess the review text: lowercase, tokenize, remove stopwords, and stem</span><br>df[<span class="hljs-string">&#x27;preprocessed_review&#x27;</span>] = df[<span class="hljs-string">&#x27;review&#x27;</span>].apply(preprocess_review)<br><br><span class="hljs-comment"># Get the embeddings for each review</span><br>review_embeddings = []<br><span class="hljs-keyword">for</span> review <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;preprocessed_review&#x27;</span>]:<br>    review_embeddings.append(get_embedding(review, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>))<br>    <br><span class="hljs-comment"># Get the index of the input coffee name</span><br><span class="hljs-keyword">try</span>:<br>    input_coffee_index = df[df[<span class="hljs-string">&#x27;name&#x27;</span>] == input_coffee_name].index[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">except</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sorry, we don&#x27;t have that coffee in our database. Please try again.&quot;</span>)<br>    exit()<br>    <br><span class="hljs-comment"># Calculate the cosine similarity between the input coffee&#x27;s review and all other reviews</span><br>similarities = []<br>input_review_embedding = review_embeddings[input_coffee_index]<br><span class="hljs-keyword">for</span> review_embedding <span class="hljs-keyword">in</span> review_embeddings:<br>    similarity = cosine_similarity(input_review_embedding, review_embedding)<br>    similarities.append(similarity)<br><br><span class="hljs-comment"># Get the indices of the most similar reviews (excluding the input coffee&#x27;s review itself)</span><br>most_similar_indices = np.argsort(similarities)[-<span class="hljs-number">6</span>:-<span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># why -1? because the last one is the input coffee itself</span><br><br><span class="hljs-comment"># Get the names of the most similar coffees</span><br>similar_coffee_names = df.iloc[most_similar_indices][<span class="hljs-string">&#x27;name&#x27;</span>].tolist()<br><br><span class="hljs-comment"># Print the results</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;The most similar coffees to &#123;&#125; are:&quot;</span>.<span class="hljs-built_in">format</span>(input_coffee_name))<br><span class="hljs-keyword">for</span> coffee_name <span class="hljs-keyword">in</span> similar_coffee_names:<br>    <span class="hljs-built_in">print</span>(coffee_name)<br></code></pre></td></tr></table></figure>

<h3 id="Making-a-“Fuzzier”-search"><a href="#Making-a-“Fuzzier”-search" class="headerlink" title="Making a “Fuzzier” search"></a>Making a “Fuzzier” search</h3><ul>
<li>The previous code has limitation which need exact match for the input and existing coffee name list. </li>
<li>“Fuzzier” search leverage fuzzy search technique, such as “<em>Levenshtein distance</em>“ or cosine similarity search between the user input and the coffe names.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">from</span> openai.embeddings_utils <span class="hljs-keyword">import</span> get_embedding, cosine_similarity<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">download_nltk_data</span>():<br>    <span class="hljs-keyword">try</span>:<br>        nltk.data.find(<span class="hljs-string">&#x27;tokenizers/punkt&#x27;</span>)<br>    <span class="hljs-keyword">except</span> LookupError:<br>        nltk.download(<span class="hljs-string">&#x27;punkt&#x27;</span>)<br>    <span class="hljs-keyword">try</span>:<br>        nltk.data.find(<span class="hljs-string">&#x27;corpora/stopwords&#x27;</span>)<br>    <span class="hljs-keyword">except</span> LookupError:<br>        nltk.download(<span class="hljs-string">&#x27;stopwords&#x27;</span>)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_review</span>(<span class="hljs-params">review</span>):<br>    <span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords<br>    <span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> PorterStemmer<br>    stopwords = <span class="hljs-built_in">set</span>(stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>))<br>    stemmer = PorterStemmer()<br>    tokens = nltk.word_tokenize(review.lower())<br>    tokens = [token <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords]<br>    tokens = [stemmer.stem(token) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join(tokens)<br><br>init_api()<br><br>download_nltk_data()<br><br><span class="hljs-comment"># Read user input</span><br>input_coffee_name = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Enter a coffee name: &quot;</span>)<br><br><span class="hljs-comment"># Load the CSV file into a Pandas DataFrame </span><br><span class="hljs-comment"># (only the first 50 rows for now to speed up the demo and avoid paying for too many API calls)</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;simplified_coffee.csv&#x27;</span>, nrows=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Preprocess the review text: lowercase, tokenize, remove stopwords, and stem</span><br>df[<span class="hljs-string">&#x27;preprocessed_review&#x27;</span>] = df[<span class="hljs-string">&#x27;review&#x27;</span>].apply(preprocess_review)<br><br><span class="hljs-comment"># Get the embeddings for each review</span><br>review_embeddings = []<br><span class="hljs-keyword">for</span> review <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;preprocessed_review&#x27;</span>]:<br>    review_embeddings.append(get_embedding(review, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>))<br>    <br><span class="hljs-comment"># Get the index of the input coffee name, with &quot;fuzzy search&quot;</span><br><span class="hljs-keyword">try</span>:<br>    input_coffee_index = df[df[<span class="hljs-string">&#x27;name&#x27;</span>] == input_coffee_name].index[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">except</span> IndexError:<br>    <span class="hljs-comment"># get the embeddings for each name</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sorry, we don&#x27;t have that coffee in our database. We will try to find the closest match.&quot;</span>)<br>    name_embeddings = []<br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;name&#x27;</span>]:<br>        name_embeddings.append(get_embedding(name, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>))<br>    <span class="hljs-comment"># perform a cosine similarity search on the input coffee name</span><br>    input_coffee_embedding = get_embedding(input_coffee_name, engine=<span class="hljs-string">&#x27;text-embedding-ada-002&#x27;</span>)<br>    _similarities = []<br>    <span class="hljs-keyword">for</span> name_embedding <span class="hljs-keyword">in</span> name_embeddings:<br>        _similarities.append(cosine_similarity(input_coffee_embedding, name_embedding))<br>    <br>    input_coffee_index = _similarities.index(<span class="hljs-built_in">max</span>(_similarities))<br><span class="hljs-keyword">except</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sorry, we don&#x27;t have that coffee in our database. Please try again.&quot;</span>)<br>    exit()<br>    <br><span class="hljs-comment"># Calculate the cosine similarity between the input coffee&#x27;s review and all other reviews</span><br>similarities = []<br>input_review_embedding = review_embeddings[input_coffee_index]<br><span class="hljs-keyword">for</span> review_embedding <span class="hljs-keyword">in</span> review_embeddings:<br>    similarity = cosine_similarity(input_review_embedding, review_embedding)<br>    similarities.append(similarity)<br><br><span class="hljs-comment"># Get the indices of the most similar reviews (excluding the input coffee&#x27;s review itself)</span><br>most_similar_indices = np.argsort(similarities)[-<span class="hljs-number">6</span>:-<span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># why -1? because the last one is the input coffee itself</span><br><br><span class="hljs-comment"># Get the names of the most similar coffees</span><br>similar_coffee_names = df.iloc[most_similar_indices][<span class="hljs-string">&#x27;name&#x27;</span>].tolist()<br><br><span class="hljs-comment"># Print the results</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;The most similar coffees to &#123;&#125; are:&quot;</span>.<span class="hljs-built_in">format</span>(input_coffee_name))<br><span class="hljs-keyword">for</span> coffee_name <span class="hljs-keyword">in</span> similar_coffee_names:<br>    <span class="hljs-built_in">print</span>(coffee_name)<br></code></pre></td></tr></table></figure>

<h3 id="Predicting-News-category-using-embedding-零样本"><a href="#Predicting-News-category-using-embedding-零样本" class="headerlink" title="Predicting News category using embedding(零样本)"></a>Predicting News category using embedding(零样本)</h3><p> This example will introduce a zero-shot news classifier that predicts the category of a news article.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">from</span> openai.embeddings_utils <span class="hljs-keyword">import</span> get_embedding, cosine_similarity<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br>    <br>init_api()<br><br>categories = [<br>    <span class="hljs-string">&quot;POLITICS&quot;</span>,<br>    <span class="hljs-string">&quot;WELLNESS&quot;</span>,<br>    <span class="hljs-string">&quot;ENTERTAINMENT&quot;</span>,<br>    <span class="hljs-string">&quot;TRAVEL&quot;</span>,<br>    <span class="hljs-string">&quot;STYLE &amp; BEAUTY&quot;</span>,<br>    <span class="hljs-string">&quot;PARENTING&quot;</span>,<br>    <span class="hljs-string">&quot;HEALTHY LIVING&quot;</span>,<br>    <span class="hljs-string">&quot;QUEER VOICES&quot;</span>,<br>    <span class="hljs-string">&quot;FOOD &amp; DRINK&quot;</span>,<br>    <span class="hljs-string">&quot;BUSINESS&quot;</span>,<br>    <span class="hljs-string">&quot;COMEDY&quot;</span>,<br>    <span class="hljs-string">&quot;SPORTS&quot;</span>,<br>    <span class="hljs-string">&quot;BLACK VOICES&quot;</span>,<br>    <span class="hljs-string">&quot;HOME &amp; LIVING&quot;</span>,<br>    <span class="hljs-string">&quot;PARENTS&quot;</span>,<br>]<br><br><span class="hljs-comment"># define a function to classify a sentence</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">classify_sentence</span>(<span class="hljs-params">sentence</span>):<br>    <span class="hljs-comment">#Get the embedding of the sentence</span><br>    sentence_embedding = get_embedding(sentence, engine=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>)<br>    <br>    <span class="hljs-comment">#Calculate the similarity score between the sentence and each category</span><br>    similarity_scores = &#123;&#125;<br>    <span class="hljs-keyword">for</span> category <span class="hljs-keyword">in</span> categories:<br>        category_embeddings = get_embedding(category, engine=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>)<br>        similarity_scores[category] = cosine_similarity(sentence_embedding, category_embeddings)<br>        <br>    <span class="hljs-comment"># Return the category with the highest similarity score</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(similarity_scores, key=similarity_scores.get)<br><br>sentences = [<br>    <span class="hljs-string">&quot;1 dead and 3 injured in El Paso, Texas, mall shooting&quot;</span>,<br>    <span class="hljs-string">&quot;Director Owen Kline Calls Funny Pages His ‘Self-Critical’ Debut&quot;</span>,<br>    <span class="hljs-string">&quot;15 spring break ideas for families that want to get away&quot;</span>,<br>    <span class="hljs-string">&quot;The US is preparing to send more troops to the Middle East&quot;</span>,<br>    <span class="hljs-string">&quot;Bruce Willis&#x27; &#x27;condition has progressed&#x27; to frontotemporal dementia, his family says&quot;</span>,<br>    <span class="hljs-string">&quot;Get an inside look at Universal’s new Super Nintendo World&quot;</span>,<br>    <span class="hljs-string">&quot;Barcelona 2-2 Manchester United: Marcus Rashford shines but Raphinha salvages draw for hosts&quot;</span>,<br>    <span class="hljs-string">&quot;Chicago bulls win the NBA championship&quot;</span>,<br>    <span class="hljs-string">&quot;The new iPhone 12 is now available&quot;</span>,<br>    <span class="hljs-string">&quot;Scientists discover a new dinosaur species&quot;</span>,<br>    <span class="hljs-string">&quot;The new coronavirus vaccine is now available&quot;</span>,<br>    <span class="hljs-string">&quot;The new Star Wars movie is now available&quot;</span>,<br>    <span class="hljs-string">&quot;Amazon stock hits a new record high&quot;</span>,<br>]<br><br><span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;:50&#125; category is &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(sentence, classify_sentence(sentence)))<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure>

<h3 id="Evaluating-the-accuracy-of-a-Zero-Shot-classifier-零样本"><a href="#Evaluating-the-accuracy-of-a-Zero-Shot-classifier-零样本" class="headerlink" title="Evaluating the accuracy of a Zero-Shot classifier (零样本)"></a>Evaluating the accuracy of a Zero-Shot classifier (零样本)</h3><p>It looks like the previous classifier is almost perfect but there is a way to understand if it is really accurate and generate an accuracy score.</p>
<p>We are going to start by downloading this dataset from kaggle and saving it under&#x2F;data&#x2F;News_-Category_Dataset_v3.json.</p>
<p>This dataset contains around 210k news headlines from 2012 to 2022 from HuffPost.The dataset classifies the headlines of each article into a category.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> openai.embeddings_utils <span class="hljs-keyword">import</span> get_embedding, cosine_similarity<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br>    <br>init_api()<br><br>categories = [<br>    <span class="hljs-string">&quot;POLITICS&quot;</span>,<br>    <span class="hljs-string">&quot;WELLNESS&quot;</span>,<br>    <span class="hljs-string">&quot;ENTERTAINMENT&quot;</span>,<br>    <span class="hljs-string">&quot;TRAVEL&quot;</span>,<br>    <span class="hljs-string">&quot;STYLE &amp; BEAUTY&quot;</span>,<br>    <span class="hljs-string">&quot;PARENTING&quot;</span>,<br>    <span class="hljs-string">&quot;HEALTHY LIVING&quot;</span>,<br>    <span class="hljs-string">&quot;QUEER VOICES&quot;</span>,<br>    <span class="hljs-string">&quot;FOOD &amp; DRINK&quot;</span>,<br>    <span class="hljs-string">&quot;BUSINESS&quot;</span>,<br>    <span class="hljs-string">&quot;COMEDY&quot;</span>,<br>    <span class="hljs-string">&quot;SPORTS&quot;</span>,<br>    <span class="hljs-string">&quot;BLACK VOICES&quot;</span>,<br>    <span class="hljs-string">&quot;HOME &amp; LIVING&quot;</span>,<br>    <span class="hljs-string">&quot;PARENTS&quot;</span>,<br>]<br><br><span class="hljs-comment"># Define a function to classify a sentence</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">classify_sentence</span>(<span class="hljs-params">sentence</span>):<br>    <span class="hljs-comment"># Get the embedding of the sentence</span><br>    sentence_embedding = get_embedding(sentence, engine=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>)<br>    <span class="hljs-comment"># Calculate the similarity score between the sentence and each category</span><br>    similarity_scores = &#123;&#125;<br>    <span class="hljs-keyword">for</span> category <span class="hljs-keyword">in</span> categories:<br>        category_embeddings = get_embedding(category, engine=<span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>)<br>        similarity_scores[category] = cosine_similarity(sentence_embedding, category_embeddings)<br>        <span class="hljs-comment"># Return the category with the highest similarity score</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(similarity_scores, key=similarity_scores.get)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_precision</span>(<span class="hljs-params">categories</span>):<br>    <span class="hljs-comment"># Load the dataset</span><br>    df = pd.read_json(<span class="hljs-string">&quot;News_Category_Dataset_v3.json&quot;</span>, lines=<span class="hljs-literal">True</span>).head(<span class="hljs-number">20</span>)<br>    y_true = []<br>    y_pred = []<br>    <br>    <span class="hljs-comment"># Classify each sentence</span><br>    <span class="hljs-keyword">for</span> _, row <span class="hljs-keyword">in</span> df.iterrows():<br>        true_category = row[<span class="hljs-string">&#x27;category&#x27;</span>]<br>        predicted_category = classify_sentence(row[<span class="hljs-string">&#x27;headline&#x27;</span>])<br>        <br>        y_true.append(true_category)<br>        y_pred.append(predicted_category)<br>        <br>        <span class="hljs-comment"># Calculate the precision score</span><br>        <span class="hljs-keyword">return</span> precision_score(y_true, y_pred, average=<span class="hljs-string">&#x27;micro&#x27;</span>, labels=categories)<br>    <br>precision_evaluated = evaluate_precision(categories)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Precision: &#123;:.2f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(precision_evaluated))<br></code></pre></td></tr></table></figure>

<h2 id="Fine-Tuning-amp-Best-Practices"><a href="#Fine-Tuning-amp-Best-Practices" class="headerlink" title="Fine Tuning &amp; Best Practices"></a>Fine Tuning &amp; Best Practices</h2><h3 id="Few-short-learning-and-example-of-Fine-Tuning-practice"><a href="#Few-short-learning-and-example-of-Fine-Tuning-practice" class="headerlink" title="Few short learning and example of Fine Tuning practice"></a>Few short learning and example of Fine Tuning practice</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">1. create a json file with below <span class="hljs-built_in">test</span> prompts</span><br>[<br>&#123;<br>    &quot;prompt&quot;:&quot;When do I have to start the heater?&quot;,<br>    &quot;completion&quot;:&quot;Every day in the morning at 7AM. You should stop it at 2PM&quot;<br>&#125;,<br><br>&#123;<br>    &quot;prompt&quot;:&quot;Where is the garage remote control?&quot;,<br>    &quot;completion&quot;:&quot;Next to the yellow door, on the key ring&quot;<br>&#125;,<br><br>&#123;<br>    &quot;prompt&quot;:&quot;Is it necessary to program the scent diffuser every day?&quot;,<br>    &quot;completion&quot;:&quot;The scent diffuser is already programmed, you just need to recharge it when its battery is low&quot;<br>&#125;<br>]<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">2. generate the jasonl file based on the previous json file</span><br>root@c1ws-test:~/jupyter_workspace# cat data.json<br>root@c1ws-test:~/jupyter_workspace# openai tools fine_tunes.prepare_data -f data.json<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">3. tune the new model based on model: davinci</span><br>root@c1ws-test:~/jupyter_workspace# export OPENAI_API_KEY=&quot;YOUR_API_KEY&quot;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## Optional to add suffix of the new model name as below:</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">root@c1ws-test:~/jupyter_workspace<span class="hljs-comment"># openai api fine_tunes.create  -t &quot;data_prepared.jsonl&quot; -m davinci --suffix &quot;felix_yang&quot;</span></span><br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.create  -t &quot;data_prepared.jsonl&quot; -m davinci<br>Upload progress: 100%|████████████████████████████████████████████████████████████████████| 417/417 [00:00&lt;00:00, 540kit/s]<br>Uploaded file from data_prepared.jsonl: file-WIRS3kIX67OFCmGdBKlYhawT<br>Created fine-tune: ft-vs2MUECcW4S92WGroV4xtfuc<br>Streaming events until fine-tuning is complete...<br><br>(Ctrl-C will interrupt the stream, but not cancel the fine-tune)<br>[2023-06-21 03:28:41] Created fine-tune: ft-vs2MUECcW4S92WGroV4xtfuc<br><br>Stream interrupted (client disconnected).<br>To resume the stream, run:<br><br>  openai api fine_tunes.follow -i ft-vs2MUECcW4S92WGroV4xtfuc<br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.follow -i ft-vs2MUECcW4S92WGroV4xtfuc<br>[2023-06-21 03:28:41] Created fine-tune: ft-vs2MUECcW4S92WGroV4xtfuc<br>[2023-06-21 03:29:52] Fine-tune costs $0.01<br>[2023-06-21 03:29:53] Fine-tune enqueued. Queue number: 0<br>[2023-06-21 03:30:05] Fine-tune started<br><br>Stream interrupted (client disconnected).<br>To resume the stream, run:<br><br>  openai api fine_tunes.follow -i ft-vs2MUECcW4S92WGroV4xtfuc<br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.follow -i ft-vs2MUECcW4S92WGroV4xtfuc<br>[2023-06-21 03:28:41] Created fine-tune: ft-vs2MUECcW4S92WGroV4xtfuc<br>[2023-06-21 03:29:52] Fine-tune costs $0.01<br>[2023-06-21 03:29:53] Fine-tune enqueued. Queue number: 0<br>[2023-06-21 03:30:05] Fine-tune started<br>[2023-06-21 03:32:56] Completed epoch 1/4<br>[2023-06-21 03:32:57] Completed epoch 2/4<br>[2023-06-21 03:32:58] Completed epoch 3/4<br>[2023-06-21 03:32:59] Completed epoch 4/4<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">4. Check the new model <span class="hljs-built_in">id</span></span><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.list<br>&#123;<br>  &quot;object&quot;: &quot;list&quot;,<br>  &quot;data&quot;: [<br>    &#123;<br>      &quot;object&quot;: &quot;fine-tune&quot;,<br>      &quot;id&quot;: &quot;ft-vs2MUECcW4S92WGroV4xtfuc&quot;,   ## Fine_tune_job_id<br>      &quot;hyperparams&quot;: &#123;<br>        &quot;n_epochs&quot;: 4,<br>        &quot;batch_size&quot;: 1,<br>        &quot;prompt_loss_weight&quot;: 0.01,<br>        &quot;learning_rate_multiplier&quot;: 0.1<br>      &#125;,<br>      &quot;organization_id&quot;: &quot;org-1kpSRIJZFLe1LzYA6NIMCm20&quot;,<br>      &quot;model&quot;: &quot;davinci&quot;,<br>      &quot;training_files&quot;: [<br>        &#123;<br>          &quot;object&quot;: &quot;file&quot;,<br>          &quot;id&quot;: &quot;file-WIRS3kIX67OFCmGdBKlYhawT&quot;,<br>          &quot;purpose&quot;: &quot;fine-tune&quot;,<br>          &quot;filename&quot;: &quot;data_prepared.jsonl&quot;,<br>          &quot;bytes&quot;: 417,<br>          &quot;created_at&quot;: 1687318121,<br>          &quot;status&quot;: &quot;processed&quot;,<br>          &quot;status_details&quot;: null<br>        &#125;<br>      ],<br>      &quot;validation_files&quot;: [],<br>      &quot;result_files&quot;: [<br>        &#123;<br>          &quot;object&quot;: &quot;file&quot;,<br>          &quot;id&quot;: &quot;file-4lcuZduyevJH94dl7nkf4BPO&quot;,<br>          &quot;purpose&quot;: &quot;fine-tune-results&quot;,<br>          &quot;filename&quot;: &quot;compiled_results.csv&quot;,<br>          &quot;bytes&quot;: 754,<br>          &quot;created_at&quot;: 1687318420,<br>          &quot;status&quot;: &quot;processed&quot;,<br>          &quot;status_details&quot;: null<br>        &#125;<br>      ],<br>      &quot;created_at&quot;: 1687318121,<br>      &quot;updated_at&quot;: 1687318421,<br>      &quot;status&quot;: &quot;succeeded&quot;,<br>      &quot;fine_tuned_model&quot;: &quot;davinci:ft-personal-2023-06-21-03-33-39&quot;  # New model id<br>    &#125;<br>  ]<br>&#125;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">5. Test the new model</span><br><br>root@c1ws-test:~/jupyter_workspace# export FINE_TUNED_MODEL=&quot;davinci:ft-personal-2023-06-21-03-33-39&quot;<br>root@c1ws-test:~/jupyter_workspace# openai api completions.create -m $FINE_TUNED_MODEL -p &quot;When do I have to start the heater?&quot;<br>When do I have to start the heater?When do I have to turn off the A/C?How low can I<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">6. Analyze the new model</span><br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.results -i &quot;ft-vs2MUECcW4S92WGroV4xtfuc&quot;<br>step,elapsed_tokens,elapsed_examples,training_loss,training_sequence_accuracy,training_token_accuracy<br>1,33,1,1.262732845058199,0.0,0.6<br>2,66,2,1.6095716556394473,0.0,0.17647058823529413<br>3,91,3,1.6150656826297443,0.0,0.45454545454545453<br>4,124,4,1.466446138578467,0.0,0.29411764705882354<br>5,149,5,1.484918415422241,0.0,0.45454545454545453<br>6,182,6,1.0398217318346723,0.0,0.55<br>7,215,7,1.0021467336965726,0.0,0.55<br>8,240,8,1.3121158500760792,0.0,0.45454545454545453<br>9,273,9,1.2723229727894068,0.0,0.4117647058823529<br>10,298,10,1.260173139721155,0.0,0.45454545454545453<br>11,331,11,1.2538491002004593,0.0,0.47058823529411764<br>12,364,12,0.9169519251119346,0.0,0.55<br>13,397,13,1.246762776928954,0.0,0.4117647058823529<br>14,422,14,1.242958545796573,0.0,0.45454545454545453<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">7. Delete the model</span><br>- CLI:<br>root@c1ws-test:~/jupyter_workspace# openai api models.delete -i &quot;davinci:ft-personal-2023-06-21-03-33-39&quot;<br>&#123;<br>  &quot;id&quot;: &quot;davinci:ft-personal-2023-06-21-03-33-39&quot;,<br>  &quot;object&quot;: &quot;model&quot;,<br>  &quot;deleted&quot;: true<br>&#125;<br><br>- Python<br>openai.Model.delete(&quot;davinci:ft-personal-2023-06-21-03-33-39&quot;)<br><br>- cURL<br>curl -X &quot;DELETE&quot; https://api.openai.com/v1/models/&lt;FINE_TUNED_MODEL&gt; -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot;<br><br></code></pre></td></tr></table></figure>



<h3 id="What’s-the-best-practice-Datasets-Prompts-and-Completions"><a href="#What’s-the-best-practice-Datasets-Prompts-and-Completions" class="headerlink" title="What’s the best practice - Datasets, Prompts and Completions"></a>What’s the best practice - Datasets, Prompts and Completions</h3><ul>
<li>Each Prompt Should End With a Fixed Separator</li>
<li>Each Completion Should Start With a Whitespace</li>
<li>Each Completion Should End With a Fixed-Stop Sequence</li>
<li>Fine-Tuning Performs Better With More High-Quality Examples</li>
<li>For the dataset, converting the input data into natural language will likely result in better performance. This is evenclearer when you are building a generative model.</li>
<li>Review Your Data for Offensive Content</li>
<li>Review the Type and Structure of Your Dataset</li>
<li>Analyze Your Model</li>
</ul>
<blockquote>
<p>root@c1ws-test:~&#x2F;jupyter_workspace# openai api fine_tunes.results -i “ft-vs2MUECcW4S92WGroV4xtfuc”<br>step,elapsed_tokens,elapsed_examples,training_loss,training_sequence_accuracy,training_token_accuracy<br>1,33,1,1.262732845058199,0.0,0.6<br>2,66,2,1.6095716556394473,0.0,0.17647058823529413<br>3,91,3,1.6150656826297443,0.0,0.45454545454545453<br>4,124,4,1.466446138578467,0.0,0.29411764705882354<br>5,149,5,1.484918415422241,0.0,0.45454545454545453<br>6,182,6,1.0398217318346723,0.0,0.55<br>7,215,7,1.0021467336965726,0.0,0.55<br>8,240,8,1.3121158500760792,0.0,0.45454545454545453<br>9,273,9,1.2723229727894068,0.0,0.4117647058823529<br>10,298,10,1.260173139721155,0.0,0.45454545454545453<br>11,331,11,1.2538491002004593,0.0,0.47058823529411764<br>12,364,12,0.9169519251119346,0.0,0.55<br>13,397,13,1.246762776928954,0.0,0.4117647058823529<br>14,422,14,1.242958545796573,0.0,0.45454545454545453</p>
<ol>
<li>“step”: This column shows the training step number or the number of iterations of the trainingprocess.</li>
<li>“elapsed_tokens”: Shows the number of tokens processed by the training process so far. A token is a unit of text, such as a word or a punctuation mark.</li>
<li>“elapsed_examples”: This is the number of examples (i.e., pieces of text) processed by the training process so far.</li>
<li>“training_loss”: This number shows the value of the loss function during training. (The loss function is a measure of how well the model is performing, with lower values indicating better performance.)</li>
<li>“training_sequence_accuracy”: The accuracy of the model in predicting the next sequence of tokens. (A sequence is a group of tokens that form a meaningful unit, such as a sentence or a paragraph.)</li>
<li>“training_token_accuracy”: This value tells us about the accuracy of the model in predicting individual tokens.<br>Some third-party tools, such as wandb⁴⁰, can also be used to analyze the results.</li>
</ol>
</blockquote>
<ul>
<li>Use validation data if needed</li>
</ul>
<blockquote>
<p>openai api fine_tunes.create -t train_data.jsonl -v validation_data.jsonl -m <engine></p>
</blockquote>
<ul>
<li><p>Tweak the Hyperparameters</p>
<ul>
<li>n_epochs</li>
<li>batch_size</li>
<li>learning_rate_multiplier</li>
</ul>
</li>
<li><p>Use Ada</p>
<ul>
<li>When tackling classification problems, the Ada model is a good option. It performs only slightly<br>worse than Davinci once fine-tuned, at the same time it is considerably faster and more affordable</li>
</ul>
</li>
<li><p>Use Single-Token Classes</p>
<ul>
<li>save token numbers</li>
<li>much fast<ul>
<li>“sports and entertainment”:</li>
<li>{prompt:”The Los Angeles Lakers won the NBA championship last year.”, completion: “sports and entertainment”}</li>
<li>1(for sports and entertainment):</li>
<li>{prompt:”The Los Angeles Lakers won the NBA championship last year.”, completion: “1”}</li>
</ul>
</li>
</ul>
</li>
<li><p>Other Considerations for Classification</p>
<ul>
<li>Ensure that the prompt and completion combined do not exceed 2048 tokens, including the separator.</li>
<li>Try to provide at least 100 examples for each class.</li>
<li>The separator should not be used within the prompt text. You should remove it from the prompt if it’s the case. Example: If your separator is !#! you should preprocess the text of the prompt to remove any !#!</li>
</ul>
</li>
</ul>
<h2 id="Advanced-Fine-Tuning-Drug-Classification"><a href="#Advanced-Fine-Tuning-Drug-Classification" class="headerlink" title="Advanced Fine Tuning: Drug Classification"></a>Advanced Fine Tuning: Drug Classification</h2><h3 id="Dataset-Used-in-the-Example"><a href="#Dataset-Used-in-the-Example" class="headerlink" title="Dataset Used in the Example"></a>Dataset Used in the Example</h3><p>In this example, we are going to use a public dataset containing drug names and the correspoinding malady, illness, or condition that they are used to treat.</p>
<p>We are going to create a model and “teach” it to predict the output based on user input.</p>
<p>The user input is the name of the drug and the output is the name of malady.<br>The dataset is available at Kaggle.com, you will need to download using the following URL:<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/saratchendra/medicine-recommendation/download?datase%5CtVersionNumber=1">https://www.kaggle.com/datasets/saratchendra/medicine-recommendation/download?datase\tVersionNumber=1</a></p>
<ul>
<li>Use sheet1</li>
<li>Use first and second column:  drug_name and reason<ul>
<li>A CN Gel(Topical) 20gmA CN Soap 75gm &#x3D;&#x3D;&gt; Acne</li>
<li>PPG Trio 1mg Tablet 10’SPPG Trio 2mg Tablet 10’S &#x3D;&#x3D;&gt; Diabetes</li>
<li>Iveomezoled 200mg Injection 500ml &#x3D;&#x3D;&gt; Fungal</li>
</ul>
</li>
</ul>
<h3 id="Preparing-the-Data-and-Launching-the-Fine-Tuning"><a href="#Preparing-the-Data-and-Launching-the-Fine-Tuning" class="headerlink" title="Preparing the Data and Launching the Fine Tuning"></a>Preparing the Data and Launching the Fine Tuning</h3><ul>
<li><p>We are going to use below format:</p>
<ul>
<li>{“prompt”:”Drug: <DRUG NAME>\nMalady:”,”completion”:” <MALADY NAME>“}</li>
</ul>
</li>
<li><p>As you can see, we will be using \nMalady: as a separator.</p>
</li>
</ul>
<blockquote>
<p>The completion will also start with a whitespace. Remember to start each completion with a<br>whitespace due to tokenization (most words are tokenized with preceding whitespace.)<br>Also, we have learned that each completion should end with a fixed stop sequence to inform the<br>model when the completion ends. for example \n, ###, END, or any other token that does not appear<br>in the completion.<br>However, in our case, this is not necessary as we are going to use a single token for classification.<br>Basically, we are going to give each malady a unique identifier. For example:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Acne: 1<br>Allergies: 2<br>Alzheimer: 3<br>..etc<br></code></pre></td></tr></table></figure>

<p>This way, the model will return a single token at inference time in all cases. This is the reason why<br>the stop sequence is not necessary.<br>To begin, use Pandas to transform the data into the desired format</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install openpyxl<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># read the first n rows</span><br>n = <span class="hljs-number">2000</span><br><br>df = pd.read_excel(<span class="hljs-string">&#x27;Medicine_description.xlsx&#x27;</span>, sheet_name=<span class="hljs-string">&#x27;Sheet1&#x27;</span>, header=<span class="hljs-number">0</span>, nrows=n)<br><br><span class="hljs-comment"># get the unique values in the Reason column</span><br>reasons = df[<span class="hljs-string">&quot;Reason&quot;</span>].unique()<br><br><span class="hljs-comment"># assign a number to each reason</span><br>reasons_dict = &#123;reason: i <span class="hljs-keyword">for</span> i, reason <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(reasons)&#125;<br><br><span class="hljs-comment"># add a new line and ### to the end of each description</span><br>df[<span class="hljs-string">&quot;Drug_Name&quot;</span>] = <span class="hljs-string">&quot;Drug: &quot;</span> + df[<span class="hljs-string">&quot;Drug_Name&quot;</span>] + <span class="hljs-string">&quot;\n&quot;</span> + <span class="hljs-string">&quot;Malady:&quot;</span><br><br><span class="hljs-comment"># concatenate the Reason and Description columns</span><br>df[<span class="hljs-string">&quot;Reason&quot;</span>] = <span class="hljs-string">&quot; &quot;</span> + df[<span class="hljs-string">&quot;Reason&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot;&quot;</span> + <span class="hljs-built_in">str</span>(reasons_dict[x]))<br><br><span class="hljs-comment"># drop the Reason column</span><br>df.drop([<span class="hljs-string">&quot;Description&quot;</span>], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># rename the columns</span><br>df.rename(columns=&#123;<span class="hljs-string">&quot;Drug_Name&quot;</span>: <span class="hljs-string">&quot;prompt&quot;</span>, <span class="hljs-string">&quot;Reason&quot;</span>: <span class="hljs-string">&quot;completion&quot;</span>&#125;, inplace=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># convert the dataframe to jsonl format</span><br>jsonl = df.to_json(orient=<span class="hljs-string">&quot;records&quot;</span>, indent=<span class="hljs-number">0</span>, lines=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># write the jsonl to a file</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;drug_malady_data.jsonl&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    f.write(jsonl)<br></code></pre></td></tr></table></figure>

<p>snippet of the generated file: drug_malady_data.jsonl</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs swift">&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: A CN Gel(Topical) 20gmA CN Soap 75gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: A Ret 0.05% Gel 20gmA Ret 0.1% Gel 20gmA Ret 0.025% Gel 20gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: ACGEL CL NANO Gel 15gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: ACGEL NANO Gel 15gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acleen 1% Lotion 25ml<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Aclene 0.10% Gel 15gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acnay Gel 10gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acne Aid Bar 50gmAcne Aid Bar 100gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acne UV Gel 60gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acne UV SPF 30 Gel 30gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acnecure Gel 20gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br>&#123;<span class="hljs-string">&quot;prompt&quot;</span>:<span class="hljs-string">&quot;Drug: Acnedap Gel 15gm<span class="hljs-subst">\n</span>Malady:&quot;</span>,<span class="hljs-string">&quot;completion&quot;</span>:<span class="hljs-string">&quot; 0&quot;</span>&#125;<br><span class="hljs-operator">...</span><br><br></code></pre></td></tr></table></figure>

<p>Now we need to train the module for a new model based on the jsonl file. Here’re the details:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><code class="hljs shell">root@c1ws-test:~/jupyter_workspace# openai tools fine_tunes.prepare_data -f drug_malady_data.jsonl<br>Analyzing...<br><br>- Your file contains 2000 prompt-completion pairs<br>- Based on your data it seems like you&#x27;re trying to fine-tune a model for classification<br>- For classification, we recommend you try one of the faster and cheaper models, such as `ada`<br>- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used fortraining<br>- All prompts end with suffix `\nMalady:`<br>- All prompts start with prefix `Drug: `<br><br>No remediations found.<br>- [Recommended] Would you like to split into training and validation set? [Y/n]: Y<br><br><br>Your data will be written to a new JSONL file. Proceed [Y/n]: Y<br><br>Wrote modified files to `drug_malady_data_prepared_train.jsonl` and `drug_malady_data_prepared_valid.jsonl`<br>Feel free to take a look!<br><br>Now use that file when fine-tuning:<br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">openai api fine_tunes.create -t <span class="hljs-string">&quot;drug_malady_data_prepared_train.jsonl&quot;</span> -v <span class="hljs-string">&quot;drug_malady_data_prepared_valid.jsonl&quot;</span> --compute_classification_metrics --classification_n_classes 7</span><br><br>After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\nMalady:` for the model to start generating completions, rather than continuing with the prompt.<br>Once your model starts training, it&#x27;ll approximately take 50.33 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.<br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.create \<br><span class="hljs-meta prompt_">&gt; </span><span class="language-bash">-t <span class="hljs-string">&quot;drug_malady_data_prepared_train.jsonl&quot;</span> \</span><br><span class="language-bash">&gt; -v <span class="hljs-string">&quot;drug_malady_data_prepared_valid.jsonl&quot;</span> \</span><br><span class="language-bash">&gt; --compute_classification_metrics \</span><br><span class="language-bash">&gt; --classification_n_classes 7 \</span><br><span class="language-bash">&gt; -m ada \</span><br><span class="language-bash">&gt; --suffix <span class="hljs-string">&quot;drug_malady_data&quot;</span></span><br>Error: No API key provided. You can set your API key in code using &#x27;openai.api_key = &lt;API-KEY&gt;&#x27;, or you can set the environment variable OPENAI_API_KEY=&lt;API-KEY&gt;). If your API key is stored in a file, you can point the openai module at it with &#x27;openai.api_key_path = &lt;PATH&gt;&#x27;. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.<br><br><br>root@c1ws-test:~/jupyter_workspace# export OPENAI_API_KEY=&quot;&lt;your key&gt;&quot;<br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.create -t &quot;drug_malady_data_prepared_train.jsonl&quot; -v &quot;drug_malady_data_prepared_valid.jsonl&quot; --compute_classification_metrics --classification_n_classes 7 -m ada --suffix &quot;drug_malady_data&quot;<br>Upload progress: 100%|██████████████████████████████████████████████████████████████████| 128k/128k [00:00&lt;00:00, 187Mit/s]<br>Uploaded file from drug_malady_data_prepared_train.jsonl: file-0NFPDCuDyX1nfLv3dFuarPDr<br>Upload progress: 100%|███████████████████████████████████████████████████████████████| 32.0k/32.0k [00:00&lt;00:00, 59.6Mit/s]<br>Uploaded file from drug_malady_data_prepared_valid.jsonl: file-kxzT0UhZZRwam7RfjYIFcuTF<br>Created fine-tune: ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br>Streaming events until fine-tuning is complete...<br><br>(Ctrl-C will interrupt the stream, but not cancel the fine-tune)<br>[2023-06-21 08:54:19] Created fine-tune: ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br><br>Stream interrupted (client disconnected).<br>To resume the stream, run:<br><br>  openai api fine_tunes.follow -i ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.follow -i ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br>[2023-06-21 08:54:19] Created fine-tune: ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br>[2023-06-21 08:56:36] Fine-tune costs $0.05<br>[2023-06-21 08:56:36] Fine-tune enqueued. Queue number: 20<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">It took mroe than 1 hour to complete the model training</span><br><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.follow -i ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br>[2023-06-21 08:54:19] Created fine-tune: ft-zk8Ojv3J1Nj1HpzRdicC2iPL<br>[2023-06-21 08:56:36] Fine-tune costs $0.05<br>[2023-06-21 08:56:36] Fine-tune enqueued. Queue number: 20<br>[2023-06-21 09:06:35] Fine-tune is in the queue. Queue number: 19<br>[2023-06-21 09:06:39] Fine-tune is in the queue. Queue number: 18<br>[2023-06-21 09:07:09] Fine-tune is in the queue. Queue number: 17<br>[2023-06-21 09:08:12] Fine-tune is in the queue. Queue number: 16<br>[2023-06-21 09:09:27] Fine-tune is in the queue. Queue number: 15<br>[2023-06-21 09:10:00] Fine-tune is in the queue. Queue number: 14<br>[2023-06-21 09:10:55] Fine-tune is in the queue. Queue number: 13<br>[2023-06-21 09:11:40] Fine-tune is in the queue. Queue number: 12<br>[2023-06-21 09:13:14] Fine-tune is in the queue. Queue number: 11<br>[2023-06-21 09:13:48] Fine-tune is in the queue. Queue number: 10<br>[2023-06-21 09:15:02] Fine-tune is in the queue. Queue number: 9<br>[2023-06-21 09:15:08] Fine-tune is in the queue. Queue number: 8<br>[2023-06-21 09:18:55] Fine-tune is in the queue. Queue number: 7<br>[2023-06-21 09:19:27] Fine-tune is in the queue. Queue number: 6<br>[2023-06-21 09:30:57] Fine-tune is in the queue. Queue number: 5<br>[2023-06-21 09:32:08] Fine-tune is in the queue. Queue number: 4<br>[2023-06-21 09:32:29] Fine-tune is in the queue. Queue number: 3<br>[2023-06-21 09:33:03] Fine-tune is in the queue. Queue number: 2<br>[2023-06-21 09:33:54] Fine-tune is in the queue. Queue number: 1<br>[2023-06-21 09:37:01] Fine-tune is in the queue. Queue number: 0<br>[2023-06-21 09:37:21] Fine-tune started<br>[2023-06-21 09:42:31] Completed epoch 1/4<br>[2023-06-21 09:52:33] Completed epoch 3/4<br>[2023-06-21 09:57:33] Completed epoch 4/4<br>[2023-06-21 09:58:06] Uploaded model: ada:ft-personal:drug-malady-data-2023-06-21-09-58-05<br>[2023-06-21 09:58:07] Uploaded result file: file-tzqW6Vjcqg9thdkCBzgihH8M<br>[2023-06-21 09:58:07] Fine-tune succeeded<br><br>Job complete! Status: succeeded 🎉<br>Try out your fine-tuned model:<br><br>openai api completions.create -m ada:ft-personal:drug-malady-data-2023-06-21-09-58-05 -p &lt;YOUR_PROMPT&gt;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">List the generated new models</span><br>root@c1ws-test:~/jupyter_workspace# openai api fine_tunes.list<br>&#123;<br>  &quot;object&quot;: &quot;list&quot;,<br>  &quot;data&quot;: [<br>    &#123;<br>      &quot;object&quot;: &quot;fine-tune&quot;,<br>      &quot;id&quot;: &quot;ft-zk8Ojv3J1Nj1HpzRdicC2iPL&quot;,<br>      &quot;hyperparams&quot;: &#123;<br>        &quot;n_epochs&quot;: 4,<br>        &quot;batch_size&quot;: 2,<br>        &quot;prompt_loss_weight&quot;: 0.01,<br>        &quot;classification_n_classes&quot;: 7,<br>        &quot;learning_rate_multiplier&quot;: 0.1,<br>        &quot;compute_classification_metrics&quot;: true<br>      &#125;,<br>      &quot;organization_id&quot;: &quot;org-1kpSRIJZFLe1LzYA6NIMCm20&quot;,<br>      &quot;model&quot;: &quot;ada&quot;,<br>      &quot;training_files&quot;: [<br>        &#123;<br>          &quot;object&quot;: &quot;file&quot;,<br>          &quot;id&quot;: &quot;file-0NFPDCuDyX1nfLv3dFuarPDr&quot;,<br>          &quot;purpose&quot;: &quot;fine-tune&quot;,<br>          &quot;filename&quot;: &quot;drug_malady_data_prepared_train.jsonl&quot;,<br>          &quot;bytes&quot;: 128249,<br>          &quot;created_at&quot;: 1687337657,<br>          &quot;status&quot;: &quot;processed&quot;,<br>          &quot;status_details&quot;: null<br>        &#125;<br>      ],<br>      &quot;validation_files&quot;: [<br>        &#123;<br>          &quot;object&quot;: &quot;file&quot;,<br>          &quot;id&quot;: &quot;file-kxzT0UhZZRwam7RfjYIFcuTF&quot;,<br>          &quot;purpose&quot;: &quot;fine-tune&quot;,<br>          &quot;filename&quot;: &quot;drug_malady_data_prepared_valid.jsonl&quot;,<br>          &quot;bytes&quot;: 32007,<br>          &quot;created_at&quot;: 1687337659,<br>          &quot;status&quot;: &quot;processed&quot;,<br>          &quot;status_details&quot;: null<br>        &#125;<br>      ],<br>      &quot;result_files&quot;: [<br>        &#123;<br>          &quot;object&quot;: &quot;file&quot;,<br>          &quot;id&quot;: &quot;file-tzqW6Vjcqg9thdkCBzgihH8M&quot;,<br>          &quot;purpose&quot;: &quot;fine-tune-results&quot;,<br>          &quot;filename&quot;: &quot;compiled_results.csv&quot;,<br>          &quot;bytes&quot;: 168489,<br>          &quot;created_at&quot;: 1687341486,<br>          &quot;status&quot;: &quot;processed&quot;,<br>          &quot;status_details&quot;: null<br>        &#125;<br>      ],<br>      &quot;created_at&quot;: 1687337659,<br>      &quot;updated_at&quot;: 1687341487,<br>      &quot;status&quot;: &quot;succeeded&quot;,<br>      &quot;fine_tuned_model&quot;: &quot;ada:ft-personal:drug-malady-data-2023-06-21-09-58-05&quot;  ---&gt; fine tuned model ID<br>    &#125;<br>  ]<br>&#125;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Simple Test the new model</span><br>root@c1ws-test:~/jupyter_workspace# openai api completions.create -m ada:ft-personal:drug-malady-data-2023-06-21-09-58-05 -p &quot;What is &#x27;A CN Gel(Topical) 20gmA CN Soap 75gm&#x27; used for?&quot;<br>What is &#x27;A CN Gel(Topical) 20gmA CN Soap 75gm&#x27; used for? 0.0% Gel(Topical) 60gm<br><br></code></pre></td></tr></table></figure>

<h3 id="Testing-the-Fine-Tuned-Model"><a href="#Testing-the-Fine-Tuned-Model" class="headerlink" title="Testing the Fine Tuned Model"></a>Testing the Fine Tuned Model</h3><p>When the model is ready, you can test with below code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br>    <br>init_api()<br><br><span class="hljs-comment"># Configure the model ID. Change this to your model ID.</span><br>model = <span class="hljs-string">&quot;ada:ft-personal:drug-malady-data-2023-06-21-09-58-05&quot;</span><br><br><span class="hljs-comment"># Let&#x27;s use a drug from each class</span><br>drugs = [<br>    <span class="hljs-string">&quot;A CN Gel(Topical) 20gmA CN Soap 75gm&quot;</span>, <span class="hljs-comment"># Class 0</span><br>    <span class="hljs-string">&quot;Addnok Tablet 20&#x27;S&quot;</span>, <span class="hljs-comment"># Class 1</span><br>    <span class="hljs-string">&quot;ABICET M Tablet 10&#x27;s&quot;</span>, <span class="hljs-comment"># Class 2</span><br>]<br><br>class_map = &#123;<br>    <span class="hljs-number">0</span>: <span class="hljs-string">&quot;Acne&quot;</span>,<br>    <span class="hljs-number">1</span>: <span class="hljs-string">&quot;Adhd&quot;</span>,<br>    <span class="hljs-number">2</span>: <span class="hljs-string">&quot;Allergies&quot;</span>,<br>    <span class="hljs-comment"># ...</span><br>&#125;<br><br><span class="hljs-comment"># Returns a drug class for each drug</span><br><span class="hljs-keyword">for</span> drug_name <span class="hljs-keyword">in</span> drugs:<br>    prompt = <span class="hljs-string">&quot;Drug: &#123;&#125;\nMalady:&quot;</span>.<span class="hljs-built_in">format</span>(drug_name)<br>    response = openai.Completion.create(<br>        model=model,<br>        prompt= prompt,<br>        temperature=<span class="hljs-number">1</span>,<br>        max_tokens=<span class="hljs-number">1</span>,<br>    )<br>    response = response.choices[<span class="hljs-number">0</span>].text<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-built_in">print</span>(drug_name + <span class="hljs-string">&quot; is used for &quot;</span> + class_map[<span class="hljs-built_in">int</span>(response)])<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;I don&#x27;t know what &quot;</span> + drug_name + <span class="hljs-string">&quot; is used for.&quot;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure>

<h2 id="Advanced-Fine-Tuning-Creating-a-Chatbot-Assitant"><a href="#Advanced-Fine-Tuning-Creating-a-Chatbot-Assitant" class="headerlink" title="Advanced Fine Tuning: Creating a Chatbot Assitant"></a>Advanced Fine Tuning: Creating a Chatbot Assitant</h2><p>Based on previous truning model, the goal of this chapter is to create a chatbot with clarification more human friendly. </p>
<h3 id="Interactive-Classification"><a href="#Interactive-Classification" class="headerlink" title="Interactive Classification"></a>Interactive Classification</h3><p>Three functions defined:</p>
<ul>
<li>regular_discussion()</li>
<li>get_malady_name()</li>
<li>get_malady_description()</li>
</ul>
<p>The end user, when asking about a drug name will get the malady(from the fine-tuned model) and its description(from Davinci).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_api</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;.env&#x27;</span>) <span class="hljs-keyword">as</span> env:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> env:<br>            key, value = line.strip().split(<span class="hljs-string">&#x27;=&#x27;</span>)<br>            os.environ[key] = value<br>    <br>    openai.api_key = os.environ.get(<span class="hljs-string">&quot;API_KEY&quot;</span>)<br>    <br>init_api()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regular_discussion</span>(<span class="hljs-params">prompt</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    params: prompt - a string</span><br><span class="hljs-string">    Returns a response from the API using Davinci.</span><br><span class="hljs-string">    If the user asks about a drug, the function will call get_malady_name()</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    prompt = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    The following is a conversation with an AI assistant. The assistant is helpful, \</span><br><span class="hljs-string">    creative, clever, very friendly and careful with Human&#x27;s health topics</span><br><span class="hljs-string">    The AI assistant is not a doctor and does not diagnose or treat medical conditions to Human</span><br><span class="hljs-string">    The AI assistant is not a pharmacist and does not dispense or recommend medications to Human</span><br><span class="hljs-string">    The AI assistant does not provide medical advice to Human</span><br><span class="hljs-string">    The AI assistant does not provide medical and health diagnosis to Human</span><br><span class="hljs-string">    The AI assistant does not provide medical treatment to Human</span><br><span class="hljs-string">    The AI assistant does not provide medical prescriptions to Human</span><br><span class="hljs-string">    If Human writes the name of a drug the assistant will reply with &quot;######&quot;.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Human: Hi</span><br><span class="hljs-string">    AI: Hello Human. How are you? I&#x27;ll be glad to help. Give me the name of a drug a\</span><br><span class="hljs-string">    nd I&#x27;ll tell you what it&#x27;s used for.</span><br><span class="hljs-string">    Human: Vitibex</span><br><span class="hljs-string">    AI: ######</span><br><span class="hljs-string">    Human: I&#x27;m fine. How are you?</span><br><span class="hljs-string">    AI: I am fine. Thank you for asking. I&#x27;ll be glad to help. Give me the name of a\</span><br><span class="hljs-string">    drug and I&#x27;ll tell you what it&#x27;s used for.</span><br><span class="hljs-string">    Human: What is Chaos Engineering?</span><br><span class="hljs-string">    AI: I&#x27;m sorry, I am not qualified to do that. I&#x27;m only programmed to answer ques\</span><br><span class="hljs-string">    tions about drugs. Give me the name of a drug and I&#x27;ll tell you what it&#x27;s used for.</span><br><span class="hljs-string">    Human: Where is Carthage?</span><br><span class="hljs-string">    AI: I&#x27;m sorry, I am not qualified to do that. I&#x27;m only programmed to answer ques\</span><br><span class="hljs-string">    tions about drugs. Give me the name of a drug and I&#x27;ll tell you what it&#x27;s used for.</span><br><span class="hljs-string">    Human: What is Maxcet 5mg Tablet 10&#x27;S?</span><br><span class="hljs-string">    AI: ######</span><br><span class="hljs-string">    Human: What is Axepta?</span><br><span class="hljs-string">    AI: ######</span><br><span class="hljs-string">    Human: &#123;&#125;</span><br><span class="hljs-string">    AI:&quot;&quot;&quot;</span>.<span class="hljs-built_in">format</span>(prompt)<br>    <br>    <span class="hljs-comment"># Get the response from API</span><br>    response = openai.Completion.create(<br>        model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>        prompt=prompt,<br>        max_tokens=<span class="hljs-number">100</span>,<br>        stop=[<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;Human:&#x27;</span>, <span class="hljs-string">&#x27;AI:&#x27;</span>],<br>    )<br>    <br>    <span class="hljs-keyword">if</span> response.choices[<span class="hljs-number">0</span>].text.strip() == <span class="hljs-string">&quot;######&quot;</span>:<br>        get_malady_name(prompt)<br>    <span class="hljs-keyword">else</span>:<br>        final_response = response.choices[<span class="hljs-number">0</span>].text.strip() + <span class="hljs-string">&#x27;\n&#x27;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;AI: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(final_response))<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_malady_name</span>(<span class="hljs-params">drug_name</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    params: drug_name - a string</span><br><span class="hljs-string">    Returns a malady name that corresponds to a drug name from the fine-tuned model.</span><br><span class="hljs-string">    The function will call get_malady_description() to get a description of the malady.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># Configure the model ID. Change this to your model ID.</span><br>    model = <span class="hljs-string">&quot;ada:ft-personal:drug-malady-data-2023-06-21-09-58-05&quot;</span><br>    class_map = &#123;<br>        <span class="hljs-number">0</span>: <span class="hljs-string">&quot;Acne&quot;</span>,<br>        <span class="hljs-number">1</span>: <span class="hljs-string">&quot;Adhd&quot;</span>,<br>        <span class="hljs-number">2</span>: <span class="hljs-string">&quot;Allergies&quot;</span>,<br>        <span class="hljs-comment"># ...</span><br>    &#125;<br>    <br>    <span class="hljs-comment"># Returns a drug class for each drug</span><br>    prompt = <span class="hljs-string">&quot;Drug: &#123;&#125;\nMalady:&quot;</span>.<span class="hljs-built_in">format</span>(drug_name)<br>    response = openai.Completion.create(<br>        model=model,<br>        prompt=prompt,<br>        temperature=<span class="hljs-number">1</span>,<br>        max_tokens=<span class="hljs-number">1</span>, <br>    )<br>    <br>    response = response.choices[<span class="hljs-number">0</span>].text.strip()<br>    <span class="hljs-keyword">try</span>:<br>        malady = class_map[<span class="hljs-built_in">int</span>(response)]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;AI: This drug used for &#123;&#125;.&quot;</span>.<span class="hljs-built_in">format</span>(malady))<br>        <span class="hljs-built_in">print</span>(get_malady_description(malady))<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;AI: I don&#x27;t know what &#x27;&quot;</span> + drug_name + <span class="hljs-string">&quot;&#x27; is used for.&quot;</span>)<br>        <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_malady_description</span>(<span class="hljs-params">malady</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    params: drug_name - a string</span><br><span class="hljs-string">    Get a description of a malady from the API using Davinci.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    prompt = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    The following is a conversation with an AI assistant. The assistant is helpful, \</span><br><span class="hljs-string">    creative, clever, and very friendly.</span><br><span class="hljs-string">    The assistant does not provide medical advice. It only defines a malady, a disea\</span><br><span class="hljs-string">    se, or a condition.</span><br><span class="hljs-string">    If the assistant does not know the answer to a question, it will ask to rephrase\</span><br><span class="hljs-string">    it.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Q: What is &#123;&#125;?</span><br><span class="hljs-string">    A:&quot;&quot;&quot;</span>.<span class="hljs-built_in">format</span>(malady)<br>    <br>    <span class="hljs-comment"># Get the response from the API</span><br>    response = openai.Completion.create(<br>        model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br>        prompt=prompt,<br>        max_tokens=<span class="hljs-number">100</span>,<br>        stop=[<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;Q:&#x27;</span>, <span class="hljs-string">&#x27;A:&#x27;</span>],<br>    )<br>    <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].text.strip()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        regular_discussion(<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Human:&quot;</span>))<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Human:What is Fantanyl
AI: This drug used for Allergies.
Allergies are a common condition caused by an overly sensitive immune system. Symptoms usually include sneezing, runny nose, itchy eyes, and skin rash. Allergies can be triggered by something in the environment, such as pollen, pet hair, dust, or certain foods.



---------------------------------------------------------------------------

KeyboardInterrupt                         Traceback (most recent call last)

Cell In[3], line 129
    127 if __name__ == &#39;__main__&#39;:
    128     while True:
--&gt; 129         regular_discussion(input(&quot;Human:&quot;))


File ~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py:1191, in Kernel.raw_input(self, prompt)
   1189     msg = &quot;raw_input was called, but this frontend does not support input requests.&quot;
   1190     raise StdinNotImplementedError(msg)
-&gt; 1191 return self._input_request(
   1192     str(prompt),
   1193     self._parent_ident[&quot;shell&quot;],
   1194     self.get_parent(&quot;shell&quot;),
   1195     password=False,
   1196 )


File ~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py:1234, in Kernel._input_request(self, prompt, ident, parent, password)
   1231 except KeyboardInterrupt:
   1232     # re-raise KeyboardInterrupt, to truncate traceback
   1233     msg = &quot;Interrupted by user&quot;
-&gt; 1234     raise KeyboardInterrupt(msg) from None
   1235 except Exception:
   1236     self.log.warning(&quot;Invalid Message:&quot;, exc_info=True)


KeyboardInterrupt: Interrupted by user
</code></pre>
<h2 id="Intelligent-Speech-Recognition-Using-OpenAI-Whisper"><a href="#Intelligent-Speech-Recognition-Using-OpenAI-Whisper" class="headerlink" title="Intelligent Speech Recognition Using OpenAI Whisper"></a>Intelligent Speech Recognition Using OpenAI Whisper</h2>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="print-no-link">#读书笔记</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/GPT/" class="print-no-link">#GPT</a>
      
        <a href="/tags/Python/" class="print-no-link">#Python</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>OpenAI GPT For Python Developers</div>
      <div>https://blog.excelsre.com/2023/05/30/openai-gpt-for-python-developers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Felix Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年5月30日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/06/05/ke-xue-shang-wang-zui-jia-shi-jian/" title="科学上网 - 最佳实践">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">科学上网 - 最佳实践</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/05/28/hexo-bo-ke-da-jian/" title="Hexo 博客搭建">
                        <span class="hidden-mobile">Hexo 博客搭建</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://github.com/felixyh" target="_blank" rel="nofollow noopener"><span>Yixiao</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/felixyh" target="_blank" rel="nofollow noopener"><span>Yizhen</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
